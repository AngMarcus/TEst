{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import dgl\n",
    "from dgl.data.utils import load_graphs\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "random.seed(42)\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "class BrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, name, threshold=0.3, edge_ratio=0.2, node_feat_transform='pearson'):\n",
    "        t0 = time.time()\n",
    "        self.name = name\n",
    "\n",
    "        G_dataset, Labels = load_graphs(name2path[self.name])\n",
    "\n",
    "        self.node_num = G_dataset[0].ndata['N_features'].size(0)\n",
    "\n",
    "        print(\"[!] Dataset: \", self.name)\n",
    "\n",
    "        # transfer DGLHeteroGraph to DGLFormDataset\n",
    "        data = []\n",
    "        error_case = []\n",
    "        for i in range(len(G_dataset)):\n",
    "            if len(((G_dataset[i].ndata['N_features'] != 0).sum(dim=-1) == 0).nonzero()) > 0:\n",
    "                error_case.append(i)\n",
    "        print(error_case)\n",
    "        G_dataset = [n for i, n in enumerate(G_dataset) if i not in error_case]\n",
    "\n",
    "        for i in tqdm(range(len(G_dataset))):\n",
    "            if edge_ratio:\n",
    "                threshold_idx = int(len(G_dataset[i].edata['E_features']) * (1 - edge_ratio))\n",
    "                threshold = sorted(G_dataset[i].edata['E_features'].tolist())[threshold_idx]\n",
    "\n",
    "            G_dataset[i].remove_edges(torch.squeeze((torch.abs(G_dataset[i].edata['E_features']) < float(threshold)).nonzero()))\n",
    "            # G_dataset[i].edata['E_features'][G_dataset[i].edata['E_features'] < 0] = 0\n",
    "            G_dataset[i].edata['feat'] = G_dataset[i].edata['E_features'].unsqueeze(-1).clone()\n",
    "\n",
    "            if name[:-7] == 'pearson' or node_feat_transform == 'original':\n",
    "                G_dataset[i].ndata['feat'] = G_dataset[i].ndata['N_features'].clone()\n",
    "            elif node_feat_transform == 'one_hot':\n",
    "                G_dataset[i].ndata['feat'] = torch.eye(self.node_num).clone()\n",
    "            elif node_feat_transform == 'pearson':\n",
    "                G_dataset[i].ndata['feat'] = torch.from_numpy(np.corrcoef(G_dataset[i].ndata['N_features'].numpy())).clone()\n",
    "            elif node_feat_transform == '3d_coor':\n",
    "                G_dataset[i].ndata['feat'] = torch.from_numpy(self.get_3d_corr()).clone()\n",
    "            elif node_feat_transform == 'degree':\n",
    "                G_dataset[i].ndata['feat'] = G_dataset[i].in_degrees().unsqueeze(dim=1).clone()\n",
    "                # G_dataset[i].ndata['feat'] = G_dataset[i].adj().to_dense().sum(dim=0).unsqueeze(dim=1).clone()\n",
    "            elif node_feat_transform == 'adj_matrix':\n",
    "                G_dataset[i].ndata['feat'] = G_dataset[i].adj().to_dense().clone()\n",
    "            elif node_feat_transform == 'mean_std':\n",
    "                G_dataset[i].ndata['feat'] = torch.stack(torch.std_mean(G_dataset[i].ndata['N_features'], dim=-1)).T.flip(dims=[1]).clone()\n",
    "            elif node_feat_transform == 'concat':\n",
    "                # [degree | pearson | mean | std | coor]\n",
    "                degree = G_dataset[i].in_degrees().unsqueeze(dim=1).clone()\n",
    "                pearson = torch.from_numpy(np.corrcoef(G_dataset[i].ndata['N_features'].numpy()))\n",
    "                mean_std = torch.stack(torch.std_mean(G_dataset[i].ndata['N_features'], dim=-1)).T.flip(dims=[1])\n",
    "                coor = torch.from_numpy(self.get_3d_corr())\n",
    "                G_dataset[i].ndata['feat'] = torch.cat([degree, pearson, mean_std, coor], dim=-1).clone()\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            G_dataset[i].ndata.pop('N_features')\n",
    "            G_dataset[i].edata.pop('E_features')\n",
    "            data.append([G_dataset[i], Labels['glabel'].tolist()[i]])\n",
    "        \n",
    "        self.dataset = self.format_dataset(data)\n",
    "        dataset = self.format_dataset(data)\n",
    "        # this function splits data into train/val/test and returns the indices\n",
    "        self.all_idx = self.get_all_split_idx(dataset)\n",
    "\n",
    "        self.all = dataset\n",
    "        self.train = [self.format_dataset([dataset[idx] for idx in self.all_idx['train'][split_num]]) for split_num in range(10)]\n",
    "        self.val = [self.format_dataset([dataset[idx] for idx in self.all_idx['val'][split_num]]) for split_num in range(10)]\n",
    "        self.test = [self.format_dataset([dataset[idx] for idx in self.all_idx['test'][split_num]]) for split_num in range(10)]\n",
    "        \n",
    "        # After processing all graphs, use the first graph to determine feature dimension\n",
    "        self.node_feat_dim = G_dataset[0].ndata['feat'].shape[1]\n",
    "        \n",
    "        print(\"Time taken: {:.4f}s\".format(time.time()-t0))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_all_split_idx(self, dataset):\n",
    "        \"\"\"\n",
    "            - Split total number of graphs into 3 (train, val and test) in 80:10:10\n",
    "            - Stratified split proportionate to original distribution of data with respect to classes\n",
    "            - Using sklearn to perform the split and then save the indexes\n",
    "            - Preparing 10 such combinations of indexes split to be used in Graph NNs\n",
    "            - As with KFold, each of the 10 fold have unique test set.\n",
    "        \"\"\"\n",
    "        root_idx_dir = './data/{}/'.format(self.name)\n",
    "        if not os.path.exists(root_idx_dir):\n",
    "            os.makedirs(root_idx_dir)\n",
    "        all_idx = {}\n",
    "\n",
    "        # If there are no idx files, do the split and store the files\n",
    "        if not (os.path.exists(root_idx_dir + 'train.index')):\n",
    "            print(\"[!] Splitting the data into train/val/test ...\")\n",
    "\n",
    "            # Using 10-fold cross val to compare with benchmark papers\n",
    "            k_splits = 10\n",
    "\n",
    "            cross_val_fold = StratifiedKFold(n_splits=k_splits, shuffle=True)\n",
    "            k_data_splits = []\n",
    "\n",
    "            # this is a temporary index assignment, to be used below for val splitting\n",
    "            for i in range(len(dataset.graph_lists)):\n",
    "                dataset[i][0].a = lambda: None\n",
    "                setattr(dataset[i][0].a, 'index', i)\n",
    "\n",
    "            for indexes in cross_val_fold.split(dataset.graph_lists, dataset.graph_labels):\n",
    "                remain_index, test_index = indexes[0], indexes[1]\n",
    "\n",
    "                remain_set = self.format_dataset([dataset[index] for index in remain_index])\n",
    "\n",
    "                # Gets final 'train' and 'val'\n",
    "                train, val, _, __ = train_test_split(remain_set,\n",
    "                                                     range(len(remain_set.graph_lists)),\n",
    "                                                     test_size=0.111,\n",
    "                                                     stratify=remain_set.graph_labels)\n",
    "\n",
    "                train, val = self.format_dataset(train), self.format_dataset(val)\n",
    "                test = self.format_dataset([dataset[index] for index in test_index])\n",
    "\n",
    "                # Extracting only idx\n",
    "                idx_train = [item[0].a.index for item in train]\n",
    "                idx_val = [item[0].a.index for item in val]\n",
    "                idx_test = [item[0].a.index for item in test]\n",
    "\n",
    "                f_train_w = csv.writer(open(root_idx_dir + 'train.index', 'a+'))\n",
    "                f_val_w = csv.writer(open(root_idx_dir + 'val.index', 'a+'))\n",
    "                f_test_w = csv.writer(open(root_idx_dir + 'test.index', 'a+'))\n",
    "\n",
    "                f_train_w.writerow(idx_train)\n",
    "                f_val_w.writerow(idx_val)\n",
    "                f_test_w.writerow(idx_test)\n",
    "\n",
    "            print(\"[!] Splitting done!\")\n",
    "\n",
    "        # reading idx from the files\n",
    "        for section in ['train', 'val', 'test']:\n",
    "            with open(root_idx_dir + section + '.index', 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                all_idx[section] = [list(map(int, idx)) for idx in reader]\n",
    "        return all_idx\n",
    "\n",
    "    def format_dataset(self, dataset):  \n",
    "        \"\"\"\n",
    "            Utility function to recover data,\n",
    "            INTO-> dgl/pytorch compatible format \n",
    "        \"\"\"\n",
    "        graphs = [data[0] for data in dataset]\n",
    "        labels = [data[1] for data in dataset]\n",
    "\n",
    "        for graph in graphs:\n",
    "            #graph.ndata['feat'] = torch.FloatTensor(graph.ndata['feat'])\n",
    "            graph.ndata['feat'] = graph.ndata['feat'].float() # dgl 4.0\n",
    "            # adding edge features for Residual Gated ConvNet, if not there\n",
    "            if 'feat' not in graph.edata.keys():\n",
    "                edge_feat_dim = graph.ndata['feat'].shape[1] # dim same as node feature dim\n",
    "                graph.edata['feat'] = torch.ones(graph.number_of_edges(), edge_feat_dim)\n",
    "\n",
    "        return DGLFormDataset(graphs, labels)\n",
    "    \n",
    "    \n",
    "    # form a mini batch from a given list of samples = [(graph, label) pairs]\n",
    "    def collate(self, samples):\n",
    "        # The input samples is a list of pairs (graph, label).\n",
    "        graphs, labels = map(list, zip(*samples))\n",
    "        labels = torch.tensor(np.array(labels))\n",
    "        #tab_sizes_n = [ graphs[i].number_of_nodes() for i in range(len(graphs))]\n",
    "        #tab_snorm_n = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_n ]\n",
    "        #snorm_n = torch.cat(tab_snorm_n).sqrt()  \n",
    "        #tab_sizes_e = [ graphs[i].number_of_edges() for i in range(len(graphs))]\n",
    "        #tab_snorm_e = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_e ]\n",
    "        #snorm_e = torch.cat(tab_snorm_e).sqrt()\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        \n",
    "        return batched_graph, labels\n",
    "    \n",
    "    \n",
    "    # prepare dense tensors for GNNs using them; such as RingGNN, 3WLGNN\n",
    "    def collate_dense_gnn(self, samples):\n",
    "        # The input samples is a list of pairs (graph, label).\n",
    "        graphs, labels = map(list, zip(*samples))\n",
    "        labels = torch.tensor(np.array(labels))\n",
    "        #tab_sizes_n = [ graphs[i].number_of_nodes() for i in range(len(graphs))]\n",
    "        #tab_snorm_n = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_n ]\n",
    "        #snorm_n = tab_snorm_n[0][0].sqrt()  \n",
    "        \n",
    "        #batched_graph = dgl.batch(graphs)\n",
    "    \n",
    "        g = graphs[0]\n",
    "        adj = self._sym_normalize_adj(g.adjacency_matrix().to_dense())        \n",
    "        \"\"\"\n",
    "            Adapted from https://github.com/leichen2018/Ring-GNN/\n",
    "            Assigning node and edge feats::\n",
    "            we have the adjacency matrix in R^{n x n}, the node features in R^{d_n} and edge features R^{d_e}.\n",
    "            Then we build a zero-initialized tensor, say T, in R^{(1 + d_n + d_e) x n x n}. T[0, :, :] is the adjacency matrix.\n",
    "            The diagonal T[1:1+d_n, i, i], i = 0 to n-1, store the node feature of node i. \n",
    "            The off diagonal T[1+d_n:, i, j] store edge features of edge(i, j).\n",
    "        \"\"\"\n",
    "\n",
    "        zero_adj = torch.zeros_like(adj)\n",
    "        \n",
    "        in_dim = g.ndata['feat'].shape[1]\n",
    "        \n",
    "        # use node feats to prepare adj\n",
    "        adj_node_feat = torch.stack([zero_adj for j in range(in_dim)])\n",
    "        adj_node_feat = torch.cat([adj.unsqueeze(0), adj_node_feat], dim=0)\n",
    "        \n",
    "        for node, node_feat in enumerate(g.ndata['feat']):\n",
    "            adj_node_feat[1:, node, node] = node_feat\n",
    "\n",
    "        x_node_feat = adj_node_feat.unsqueeze(0)\n",
    "        \n",
    "        return x_node_feat, labels\n",
    "    \n",
    "    def _sym_normalize_adj(self, adj):\n",
    "        deg = torch.sum(adj, dim = 0)#.squeeze()\n",
    "        deg_inv = torch.where(deg>0, 1./torch.sqrt(deg), torch.zeros(deg.size()))\n",
    "        deg_inv = torch.diag(deg_inv)\n",
    "        return torch.mm(deg_inv, torch.mm(adj, deg_inv))\n",
    "\n",
    "    def _add_self_loops(self):\n",
    "\n",
    "        # function for adding self loops\n",
    "        # this function will be called only if self_loop flag is Trueq\n",
    "        for split_num in range(10):\n",
    "            self.train[split_num].graph_lists = [self_loop(g) for g in self.train[split_num].graph_lists]\n",
    "            self.val[split_num].graph_lists = [self_loop(g) for g in self.val[split_num].graph_lists]\n",
    "            self.test[split_num].graph_lists = [self_loop(g) for g in self.test[split_num].graph_lists]\n",
    "            \n",
    "        for split_num in range(10):\n",
    "            self.train[split_num] = DGLFormDataset(self.train[split_num].graph_lists, self.train[split_num].graph_labels)\n",
    "            self.val[split_num] = DGLFormDataset(self.val[split_num].graph_lists, self.val[split_num].graph_labels)\n",
    "            self.test[split_num] = DGLFormDataset(self.test[split_num].graph_lists, self.test[split_num].graph_labels)\n",
    "\n",
    "    def get_3d_corr(self):\n",
    "        path = name2path[self.name]\n",
    "        with open(path, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='\\n')\n",
    "            if self.name not in ['abide_schaefer100', 'abide_AAL116']:\n",
    "                coor = [row[1:] for row in spamreader][1:]\n",
    "            else:\n",
    "                coor = [row[1:] for row in spamreader]\n",
    "        return np.array(coor, dtype='float')\n",
    "    \n",
    "class DGLFormDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        DGLFormDataset wrapping graph list and label list as per pytorch Dataset.\n",
    "        *lists (list): lists of 'graphs' and 'labels' with same len().\n",
    "    \"\"\"\n",
    "    def __init__(self, *lists):\n",
    "        assert all(len(lists[0]) == len(li) for li in lists)\n",
    "        self.lists = lists\n",
    "        self.graph_lists = lists[0]\n",
    "        self.graph_labels = lists[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(li[index] for li in self.lists)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lists[0])    \n",
    "    \n",
    "def self_loop(g):\n",
    "    \"\"\"\n",
    "        Utility function only, to be used only when necessary as per user self_loop flag\n",
    "        : Overwriting the function dgl.transform.add_self_loop() to not miss ndata['feat'] and edata['feat']\n",
    "        \n",
    "        \n",
    "        This function is called inside a function in TUsDataset class.\n",
    "    \"\"\"\n",
    "    new_g = dgl.DGLGraph()\n",
    "    new_g.add_nodes(g.number_of_nodes())\n",
    "    new_g.ndata['feat'] = g.ndata['feat']\n",
    "    \n",
    "    src, dst = g.all_edges(order=\"eid\")\n",
    "    src = dgl.backend.zerocopy_to_numpy(src)\n",
    "    dst = dgl.backend.zerocopy_to_numpy(dst)\n",
    "    non_self_edges_idx = src != dst\n",
    "    # print(non_self_edges_idx)\n",
    "    nodes = np.arange(g.number_of_nodes())\n",
    "    new_g.add_edges(src[non_self_edges_idx], dst[non_self_edges_idx])\n",
    "    new_g.add_edges(nodes, nodes)\n",
    "    \n",
    "    # This new edata is not used since this function gets called only for GCN, GAT\n",
    "    # However, we need this for the generic requirement of ndata and edata\n",
    "    new_g.edata['feat'] = torch.zeros(new_g.number_of_edges())\n",
    "    return new_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset:  Abide100Dataset\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8675a4713274ca8a36b1de5c69d7a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.9031s\n"
     ]
    }
   ],
   "source": [
    "name2path = {\n",
    "    # Put bin files here\n",
    "    'Abide100Dataset': '/home/marcus/Brain-Network-Benchmark/data/Jupyter/abide_schaefer100.bin',\n",
    "}\n",
    "\n",
    "Abide100 = BrainDataset('Abide100Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Girvan-Newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset:  Abide100Dataset\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553d8cf19cd3444a99e7110b135ed3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.8433s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100fd35cb18d45f9915a4eecbf7df208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Graphs:   0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-01021ebe1710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Extracting features with progress tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextract_community_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_simple_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing Graphs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Example of statistical analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-01021ebe1710>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Extracting features with progress tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextract_community_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_simple_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing Graphs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Example of statistical analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-01021ebe1710>\u001b[0m in \u001b[0;36mextract_community_features\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_community_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcommunities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_girvan_newman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mnum_communities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mavg_community_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommunities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-01021ebe1710>\u001b[0m in \u001b[0;36mapply_girvan_newman\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_girvan_newman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mcommunities_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgirvan_newman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtop_level_communities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunities_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_level_communities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/community/centrality.py\u001b[0m in \u001b[0;36mgirvan_newman\u001b[0;34m(G, most_valuable_edge)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselfloop_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0m_without_most_central_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_valuable_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/community/centrality.py\u001b[0m in \u001b[0;36m_without_most_central_edges\u001b[0;34m(G, most_valuable_edge)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mnum_new_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_num_components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnum_new_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0moriginal_num_components\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0medge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmost_valuable_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mnew_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/community/centrality.py\u001b[0m in \u001b[0;36mmost_valuable_edge\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# We have guaranteed that the graph is non-empty, so this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# dictionary will never be empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mbetweenness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_betweenness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetweenness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetweenness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/classes/backends.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m                         \u001b[0;34mf\"'{name}' not implemented by {plugin_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                     )\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Keep a handle to the original function to use when testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_edge_betweenness_centrality_5\u001b[0;34m(G, k, normalized, weight, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/centrality/betweenness.py\u001b[0m in \u001b[0;36medge_betweenness_centrality\u001b[0;34m(G, k, normalized, weight, seed)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_dijkstra_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mbetweenness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_accumulate_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetweenness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;31m# rescaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove nodes to only return edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/centrality/betweenness.py\u001b[0m in \u001b[0;36m_accumulate_edges\u001b[0;34m(betweenness, S, P, sigma, s)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mbetweenness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mbetweenness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Assuming your BrainDataset class is defined and loaded as previously shared\n",
    "\n",
    "# Function to convert DGL graph to simplified NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    g = dgl.to_networkx(dgl_graph)\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Use a default weight if not specified\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "def apply_girvan_newman(graph):\n",
    "    communities_generator = nx.algorithms.community.girvan_newman(graph)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    return sorted(map(sorted, top_level_communities))\n",
    "\n",
    "def extract_community_features(graph):\n",
    "    communities = apply_girvan_newman(graph)\n",
    "    num_communities = len(communities)\n",
    "    avg_community_size = np.mean([len(c) for c in communities])\n",
    "    community_size_variance = np.var([len(c) for c in communities])\n",
    "\n",
    "    # Additional advanced feature calculations\n",
    "    edge_density_within = [nx.density(graph.subgraph(community)) for community in communities]\n",
    "    avg_edge_density_within = np.mean(edge_density_within) if edge_density_within else 0\n",
    "\n",
    "    # Cohesion and separation could be calculated based on your specific definition\n",
    "    # Here's a simple example for cohesion as average internal edge density\n",
    "    cohesion = avg_edge_density_within\n",
    "    # Separation could be defined as the difference between maximum and minimum community sizes\n",
    "    separation = max([len(c) for c in communities]) - min([len(c) for c in communities])\n",
    "\n",
    "    return (num_communities, avg_community_size, community_size_variance, avg_edge_density_within, cohesion, separation)\n",
    "\n",
    "# Extracting features with progress tracking\n",
    "features = np.array([extract_community_features(to_simple_graph(graph)) for graph in tqdm(graphs, desc=\"Processing Graphs\")])\n",
    "\n",
    "# Example of statistical analysis\n",
    "# Here, you compare the number of communities between two groups using a T-test\n",
    "labels_array = np.array(labels)\n",
    "features_0 = features[labels_array == 0]\n",
    "features_1 = features[labels_array == 1]\n",
    "\n",
    "t_stat, p_value = ttest_ind(features_0[:, 0], features_1[:, 0])  # Comparing the number of communities\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# The code above outlines the full process including converting graphs, extracting community-related features,\n",
    "# and performing a basic statistical analysis. Adjust the definitions of cohesion and separation as necessary\n",
    "# to fit your specific dataset and research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities:\n",
      "  Label 0 - Mean: 2.02, Median: 2.00, Std: 0.16\n",
      "  Label 1 - Mean: 2.04, Median: 2.00, Std: 0.27\n",
      "\n",
      "Average Community Size:\n",
      "  Label 0 - Mean: 49.72, Median: 50.00, Std: 2.31\n",
      "  Label 1 - Mean: 49.49, Median: 50.00, Std: 3.18\n",
      "\n",
      "Community Size Variance:\n",
      "  Label 0 - Mean: 2377.52, Median: 2401.00, Std: 153.08\n",
      "  Label 1 - Mean: 2366.63, Median: 2401.00, Std: 142.58\n",
      "\n",
      "Average Edge Density Within:\n",
      "  Label 0 - Mean: 0.20, Median: 0.17, Std: 0.19\n",
      "  Label 1 - Mean: 0.24, Median: 0.17, Std: 0.28\n",
      "\n",
      "Cohesion:\n",
      "  Label 0 - Mean: 0.20, Median: 0.17, Std: 0.19\n",
      "  Label 1 - Mean: 0.24, Median: 0.17, Std: 0.28\n",
      "\n",
      "Separation:\n",
      "  Label 0 - Mean: 97.55, Median: 98.00, Std: 3.73\n",
      "  Label 1 - Mean: 97.46, Median: 98.00, Std: 2.66\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you've extracted the features as per the previous example\n",
    "\n",
    "# Print basic statistics for each feature\n",
    "feature_names = ['Number of Communities', 'Average Community Size', 'Community Size Variance', \n",
    "                 'Average Edge Density Within', 'Cohesion', 'Separation']\n",
    "\n",
    "for i, name in enumerate(feature_names):\n",
    "    feature_0 = features_0[:, i]\n",
    "    feature_1 = features_1[:, i]\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Label 0 - Mean: {np.mean(feature_0):.2f}, Median: {np.median(feature_0):.2f}, Std: {np.std(feature_0):.2f}\")\n",
    "    print(f\"  Label 1 - Mean: {np.mean(feature_1):.2f}, Median: {np.median(feature_1):.2f}, Std: {np.std(feature_1):.2f}\")\n",
    "    print(\"\")\n",
    "\n",
    "# Visualization\n",
    "def plot_feature_distributions(features_0, features_1, feature_names):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, name in enumerate(feature_names):\n",
    "        sns.histplot(features_0[:, i], ax=axes[i], color=\"skyblue\", label='Label 0', kde=True, stat=\"density\", linewidth=0)\n",
    "        sns.histplot(features_1[:, i], ax=axes[i], color=\"red\", label='Label 1', kde=True, stat=\"density\", linewidth=0)\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_distributions(features_0, features_1, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kolmogorov-Smirnov (KS) Test to compare the distribution of the clustering coefficient, degree distribution, and edge weights between the two labels.\n",
    "\n",
    "##### Visualization of these distributions to provide visual insight into the differences.\n",
    "\n",
    "##### Analysis of Clustering Coefficient, Degree Distribution, and Edge Weights to explore specific network characteristics that may differ between labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1025 [00:00<00:02, 433.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset:  Abide100Dataset\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1025/1025 [00:02<00:00, 433.62it/s]\n",
      "Converting graphs:   1%|          | 9/1025 [00:00<00:12, 83.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.9866s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting graphs: 100%|██████████| 1025/1025 [00:21<00:00, 47.37it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tuple.index(x): x not in tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f336b744b052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Get clustering coefficients for each label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m clustering_label_0 = [coeff for graph, coeffs in zip(nx_graphs, clustering_coeffs) \n\u001b[0m\u001b[1;32m     21\u001b[0m                       for node, coeff in coeffs.items() if labels[graphs.index(graph)] == 0]\n\u001b[1;32m     22\u001b[0m clustering_label_1 = [coeff for graph, coeffs in zip(nx_graphs, clustering_coeffs) \n",
      "\u001b[0;32m<ipython-input-5-f336b744b052>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Get clustering coefficients for each label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m clustering_label_0 = [coeff for graph, coeffs in zip(nx_graphs, clustering_coeffs) \n\u001b[0;32m---> 21\u001b[0;31m                       for node, coeff in coeffs.items() if labels[graphs.index(graph)] == 0]\n\u001b[0m\u001b[1;32m     22\u001b[0m clustering_label_1 = [coeff for graph, coeffs in zip(nx_graphs, clustering_coeffs) \n\u001b[1;32m     23\u001b[0m                       for node, coeff in coeffs.items() if labels[graphs.index(graph)] == 1]\n",
      "\u001b[0;31mValueError\u001b[0m: tuple.index(x): x not in tuple"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs\n",
    "nx_graphs = [to_simple_graph(graph) for graph in tqdm(graphs, desc=\"Converting graphs\")]\n",
    "\n",
    "# Calculate clustering coefficients\n",
    "clustering_coeffs = [nx.clustering(g) for g in nx_graphs]\n",
    "\n",
    "# Get clustering coefficients for each label\n",
    "clustering_label_0 = [coeff for graph, coeffs in zip(nx_graphs, clustering_coeffs) \n",
    "                      for node, coeff in coeffs.items() if labels[graphs.index(graph)] == 0]\n",
    "clustering_label_1 = [coeff for graph, coeffs in zip(nx_graphs, clustering_coeffs) \n",
    "                      for node, coeff in coeffs.items() if labels[graphs.index(graph)] == 1]\n",
    "\n",
    "# Perform the Kolmogorov-Smirnov test for clustering coefficients\n",
    "ks_stats_clustering, ks_p_values_clustering = ks_2samp(clustering_label_0, clustering_label_1)\n",
    "print(\"KS test for clustering coefficients:\", ks_stats_clustering, ks_p_values_clustering)\n",
    "\n",
    "# Calculate degree distributions\n",
    "degree_distributions = [dict(g.degree()) for g in nx_graphs]\n",
    "\n",
    "# Get degree distributions for each label\n",
    "degree_label_0 = [degree for graph, degrees in zip(nx_graphs, degree_distributions) \n",
    "                  for node, degree in degrees.items() if labels[graphs.index(graph)] == 0]\n",
    "degree_label_1 = [degree for graph, degrees in zip(nx_graphs, degree_distributions) \n",
    "                  for node, degree in degrees.items() if labels[graphs.index(graph)] == 1]\n",
    "\n",
    "# Perform the Kolmogorov-Smirnov test for degree distributions\n",
    "ks_stats_degree, ks_p_values_degree = ks_2samp(degree_label_0, degree_label_1)\n",
    "print(\"KS test for degree distributions:\", ks_stats_degree, ks_p_values_degree)\n",
    "\n",
    "# Visualization of degree distributions\n",
    "degree_df = pd.DataFrame({\n",
    "    \"Degree\": [degree for degree_dict in degree_distributions for degree in degree_dict.values()],\n",
    "    \"Label\": [label for graph in nx_graphs for label in [labels[graph.graph['id']]]*nx.number_of_nodes(graph)]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=degree_df, x=\"Degree\", hue=\"Label\", element=\"step\", stat=\"density\", common_norm=False)\n",
    "plt.title(\"Degree Distributions by Label\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"Label\")\n",
    "plt.show()\n",
    "\n",
    "# Assuming graphs have weighted edges, analyze edge weight distributions\n",
    "# You'll need to adjust 'weight' to the actual attribute name used in your dataset\n",
    "if nx.get_edge_attributes(nx_graphs[0], 'weight'):\n",
    "    edge_weights = [data['weight'] for g in nx_graphs for u, v, data in g.edges(data=True)]\n",
    "    \n",
    "    # Perform the Kolmogorov-Smirnov test for edge weight distributions\n",
    "    ks_stats_edge_weight, ks_p_values_edge_weight = ks_2samp(\n",
    "        [data['weight'] for graph in nx_graphs for u, v, data in graph.edges(data=True) if labels[graph.graph['id']] == 0],\n",
    "        [data['weight'] for graph in nx_graphs for u, v, data in graph.edges(data=True) if labels[graph.graph['id']] == 1]\n",
    "    )\n",
    "    \n",
    "    print(\"KS test for edge weight distributions:\", ks_stats_edge_weight, ks_p_values_edge_weight)\n",
    "\n",
    "    # Visualization of edge weight distributions\n",
    "    edge_weight_df = pd.DataFrame({\n",
    "        \"Edge Weight\": edge_weights,\n",
    "        \"Label\": [label for graph in nx_graphs for label in [labels[graph.graph['id']]]*nx.number_of_edges(graph)]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(data=edge_weight_df, x=\"Edge Weight\", hue=\"Label\", element=\"step\", stat=\"density\", common_norm=False)\n",
    "    plt.title(\"Edge Weight Distributions by Label\")\n",
    "    plt.xlabel(\"Edge Weight\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend(title=\"Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from itertools import chain\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\" Converts a DGL graph to a simplified NetworkX graph. \"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Function to calculate edge density within communities\n",
    "def calculate_edge_density_within(graph, partition):\n",
    "    intra_edges = 0\n",
    "    total_possible_intra_edges = 0\n",
    "    for community in set(partition.values()):\n",
    "        nodes_in_community = [nodes for nodes in partition.keys() if partition[nodes] == community]\n",
    "        subgraph = graph.subgraph(nodes_in_community)\n",
    "        intra_edges += subgraph.number_of_edges()\n",
    "        total_possible_intra_edges += len(nodes_in_community) * (len(nodes_in_community) - 1) / 2\n",
    "    return intra_edges / total_possible_intra_edges if total_possible_intra_edges else 0\n",
    "\n",
    "# Function to calculate cohesion\n",
    "def calculate_cohesion(graph, partition):\n",
    "    return nx.average_clustering(graph, nodes=partition.keys(), weight='weight')\n",
    "\n",
    "# Function to apply the Girvan-Newman method and extract the top-level partition\n",
    "def apply_girvan_newman(graph):\n",
    "    communities_generator = girvan_newman(graph)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    partition = {node: i for i, community in enumerate(top_level_communities) for node in community}\n",
    "    return partition\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(graphs, labels):\n",
    "    features = {'Average Edge Density Within': [], 'Cohesion': [], 'Label': labels}\n",
    "    for graph in graphs:\n",
    "        nx_graph = to_simple_graph(graph)  # Convert DGLGraph to NetworkX graph\n",
    "        partition = apply_girvan_newman(nx_graph)\n",
    "        features['Average Edge Density Within'].append(calculate_edge_density_within(nx_graph, partition))\n",
    "        features['Cohesion'].append(calculate_cohesion(nx_graph, partition))\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Calculate the features\n",
    "features_df = extract_features(graphs, labels)\n",
    "\n",
    "# Perform t-tests\n",
    "for feature in ['Average Edge Density Within', 'Cohesion']:\n",
    "    stat, p = ttest_ind(\n",
    "        features_df[features_df['Label'] == 0][feature],\n",
    "        features_df[features_df['Label'] == 1][feature]\n",
    "    )\n",
    "    print(f\"{feature} T-test: stat = {stat:.4f}, p = {p:.4f}\")\n",
    "\n",
    "# Visualization and statistics printing\n",
    "def plot_and_print_features(features_df, feature_names):\n",
    "    for name in feature_names:\n",
    "        feature_0 = features_df[features_df['Label'] == 0][name]\n",
    "        feature_1 = features_df[features_df['Label'] == 1][name]\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Label 0 - Mean: {np.mean(feature_0):.2f}, Median: {np.median(feature_0):.2f}, Std: {np.std(feature_0):.2f}\")\n",
    "        print(f\"  Label 1 - Mean: {np.mean(feature_1):.2f}, Median: {np.median(feature_1):.2f}, Std: {np.std(feature_1):.2f}\")\n",
    "        \n",
    "        # Plot distributions\n",
    "        sns.histplot(feature_0, color=\"skyblue\", label='Label 0', kde=True, stat=\"density\", linewidth=0)\n",
    "        sns.histplot(feature_1, color=\"red\", label='Label 1', kde=True, stat=\"density\", linewidth=0)\n",
    "        plt.title(name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Execute the visualization and statistics printing function\n",
    "plot_and_print_features(features_df, ['Average Edge Density Within', 'Cohesion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Edge classification (inter vs intra community), Edge Counting, Label comparison b/w both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Louvain Edge Classification\n",
    "\n",
    "'''\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from community import community_louvain\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\" Converts a DGL graph to a simplified NetworkX graph. \"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "def detect_communities_louvain(graph):\n",
    "    partition = community_louvain.best_partition(graph)\n",
    "    return partition\n",
    "\n",
    "def classify_edges(graph, partition):\n",
    "    intra_community_edges = 0\n",
    "    inter_community_edges = 0\n",
    "    \n",
    "    for edge in graph.edges():\n",
    "        if partition[edge[0]] == partition[edge[1]]:\n",
    "            intra_community_edges += 1\n",
    "        else:\n",
    "            inter_community_edges += 1\n",
    "            \n",
    "    return intra_community_edges, inter_community_edges\n",
    "\n",
    "# Detect communities and classify edges for each graph\n",
    "edges_data = {'Label': [], 'IntraCommunityEdges': [], 'InterCommunityEdges': []}\n",
    "\n",
    "for graph, label in zip(graphs, labels):\n",
    "    partition = detect_communities_louvain(graph)\n",
    "    intra_edges, inter_edges = classify_edges(graph, partition)\n",
    "    edges_data['Label'].append(label)\n",
    "    edges_data['IntraCommunityEdges'].append(intra_edges)\n",
    "    edges_data['InterCommunityEdges'].append(inter_edges)\n",
    "\n",
    "edges_df = pd.DataFrame(edges_data)\n",
    "\n",
    "# Perform t-tests to compare edge counts between labels\n",
    "intra_t_stat, intra_p_value = ttest_ind(\n",
    "    edges_df[edges_df['Label'] == 0]['IntraCommunityEdges'],\n",
    "    edges_df[edges_df['Label'] == 1]['IntraCommunityEdges']\n",
    ")\n",
    "\n",
    "inter_t_stat, inter_p_value = ttest_ind(\n",
    "    edges_df[edges_df['Label'] == 0]['InterCommunityEdges'],\n",
    "    edges_df[edges_df['Label'] == 1]['InterCommunityEdges']\n",
    ")\n",
    "\n",
    "print(f\"Intra-Community Edges - T-statistic: {intra_t_stat}, P-value: {intra_p_value}\")\n",
    "print(f\"Inter-Community Edges - T-statistic: {inter_t_stat}, P-value: {inter_p_value}\")\n",
    "\n",
    "# Visualization\n",
    "sns.histplot(data=edges_df, x='IntraCommunityEdges', hue='Label', element='step', stat='density', common_norm=False)\n",
    "plt.title('Intra-Community Edge Counts by Label')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=edges_df, x='InterCommunityEdges', hue='Label', element='step', stat='density', common_norm=False)\n",
    "plt.title('Inter-Community Edge Counts by Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Girwan-Newman Edge Classification\n",
    "\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from networkx import edge_betweenness_centrality as betweenness\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\" Converts a DGL graph to a simplified NetworkX graph. \"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Most central edge function for Girvan-Newman\n",
    "def most_central_edge(G):\n",
    "    centrality = betweenness(G, weight='weight')\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs\n",
    "nx_graphs = [to_simple_graph(g) for g in tqdm(graphs, desc=\"Converting to simple graph\")]\n",
    "\n",
    "# Detect communities using Girvan-Newman\n",
    "def detect_communities(graph):\n",
    "    communities_generator = girvan_newman(graph, most_valuable_edge=most_central_edge)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    next_level_communities = next(communities_generator)\n",
    "    return sorted(map(sorted, next_level_communities))\n",
    "\n",
    "# Function to calculate intra- and inter-community edges\n",
    "def count_community_edges(graph, communities):\n",
    "    intra_community_edges = 0\n",
    "    inter_community_edges = 0\n",
    "    community_map = {node: idx for idx, community in enumerate(communities) for node in community}\n",
    "    for edge in graph.edges():\n",
    "        if community_map[edge[0]] == community_map[edge[1]]:\n",
    "            intra_community_edges += 1\n",
    "        else:\n",
    "            inter_community_edges += 1\n",
    "    return intra_community_edges, inter_community_edges\n",
    "\n",
    "# Apply community detection and count edges\n",
    "intra_inter_community_counts = defaultdict(list)\n",
    "for graph, label in tqdm(zip(nx_graphs, labels), total=len(labels), desc=\"Detecting communities\"):\n",
    "    communities = detect_communities(graph)\n",
    "    intra_edges, inter_edges = count_community_edges(graph, communities)\n",
    "    intra_inter_community_counts[label].append((intra_edges, inter_edges))\n",
    "\n",
    "# Prepare data for t-test\n",
    "label0_intra = [count[0] for count in intra_inter_community_counts[0]]\n",
    "label1_intra = [count[0] for count in intra_inter_community_counts[1]]\n",
    "label0_inter = [count[1] for count in intra_inter_community_counts[0]]\n",
    "label1_inter = [count[1] for count in intra_inter_community_counts[1]]\n",
    "\n",
    "# Run t-tests\n",
    "t_stat_intra, p_value_intra = ttest_ind(label0_intra, label1_intra)\n",
    "t_stat_inter, p_value_inter = ttest_ind(label0_inter, label1_inter)\n",
    "\n",
    "print(f\"Intra-community edges: T-statistic = {t_stat_intra}, P-value = {p_value_intra}\")\n",
    "print(f\"Inter-community edges: T-statistic = {t_stat_inter}, P-value = {p_value_inter}\")\n",
    "\n",
    "# Visualization of the distributions of intra- and inter-community edges\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(label0_intra, color=\"skyblue\", label='Label 0', kde=True)\n",
    "sns.histplot(label1_intra, color=\"red\", label='Label 1', kde=True)\n",
    "plt.title('Intra-Community Edges Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(label0_inter, color=\"skyblue\", label='Label 0', kde=True)\n",
    "sns.histplot(label1_inter, color=\"red\", label='Label 1', kde=True)\n",
    "plt.title('Inter-Community Edges Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine features and labels into a DataFrame for easier analysis\n",
    "features_df = pd.DataFrame(features, columns=feature_names)\n",
    "features_df['Label'] = labels_array  # Assuming labels_array is your array of labels\n",
    "\n",
    "# Compute correlations\n",
    "correlations = features_df.corr()['Label'].drop('Label')\n",
    "print(\"Feature Correlations with Labels:\\n\", correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Example function to visualize the first graph and its communities\n",
    "def visualize_graph_communities(graph, title=\"Graph with Communities\"):\n",
    "    # Detect communities\n",
    "    communities = greedy_modularity_communities(graph)\n",
    "    community_map = {}\n",
    "    for i, comm in enumerate(communities):\n",
    "        for node in comm:\n",
    "            community_map[node] = i\n",
    "    \n",
    "    # Color map based on communities\n",
    "    colors = [community_map[node] for node in graph.nodes()]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw_networkx(graph, node_color=colors, with_labels=False, node_size=50, cmap=plt.cm.jet)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Convert a DGL graph to NetworkX and visualize it\n",
    "nx_graph = to_simple_graph(graphs[0])  # Convert the first graph as an example\n",
    "visualize_graph_communities(nx_graph, \"Example Graph with Detected Communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louvain Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "import networkx as nx\n",
    "import dgl \n",
    "import pandas as pd\n",
    "\n",
    "# Your to_simple_graph function for reference\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph)\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Assuming 'graphs' is a list of DGLGraph objects\n",
    "partitions = []\n",
    "for G in graphs:\n",
    "    nx_graph = to_simple_graph(G)  # Convert DGLGraph to NetworkX graph\n",
    "    partition = community_louvain.best_partition(nx_graph)\n",
    "    partitions.append(partition)\n",
    "\n",
    "# Assuming 'labels' is a list of labels corresponding to each graph\n",
    "features_data = {\n",
    "    'Louvain_Community_Count': [len(set(partition.values())) for partition in partitions],\n",
    "    'Label': labels\n",
    "}\n",
    "\n",
    "features_df = pd.DataFrame(features_data)\n",
    "\n",
    "correlations = features_df.corr()['Label'].drop('Label')\n",
    "print(\"Feature Correlations with Labels:\\n\", correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_community_features(graph):\n",
    "    partition = community_louvain.best_partition(graph)\n",
    "    num_communities = len(set(partition.values()))\n",
    "    \n",
    "    # Community sizes\n",
    "    sizes = [list(partition.values()).count(i) for i in range(num_communities)]\n",
    "    mean_size = np.mean(sizes)\n",
    "    size_variance = np.var(sizes)\n",
    "    \n",
    "    # Modularity\n",
    "    modularity = community_louvain.modularity(partition, graph)\n",
    "    \n",
    "    # Other potential features\n",
    "    max_community_size = max(sizes)\n",
    "    min_community_size = min(sizes)\n",
    "    \n",
    "    return {\n",
    "        \"num_communities\": num_communities,\n",
    "        \"mean_community_size\": mean_size,\n",
    "        \"community_size_variance\": size_variance,\n",
    "        \"modularity\": modularity,\n",
    "        \"max_community_size\": max_community_size,\n",
    "        \"min_community_size\": min_community_size,\n",
    "    }\n",
    "\n",
    "# Calculate extended features for all graphs\n",
    "features_by_label = {\"0\": [], \"1\": []}\n",
    "\n",
    "for graph, label in zip(graphs, labels):\n",
    "    nx_graph = to_simple_graph(graph)  # Ensure this converts your graph to NetworkX\n",
    "    features = get_extended_community_features(nx_graph)\n",
    "    features_by_label[str(label)].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = [\"num_communities\", \"mean_community_size\", \"community_size_variance\",\n",
    "                \"modularity\", \"max_community_size\", \"min_community_size\"]\n",
    "\n",
    "for feature in feature_keys:\n",
    "    feature_values_0 = [f[feature] for f in features_by_label[\"0\"]]\n",
    "    feature_values_1 = [f[feature] for f in features_by_label[\"1\"]]\n",
    "    \n",
    "    t_stat, p_value = ttest_ind(feature_values_0, feature_values_1, nan_policy='omit')\n",
    "    print(f\"{feature} - T-statistic: {t_stat:.3f}, P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_feature_distributions(features_by_label, feature_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Combine data\n",
    "    data_0 = [f[feature_name] for f in features_by_label[\"0\"]]\n",
    "    data_1 = [f[feature_name] for f in features_by_label[\"1\"]]\n",
    "    data = data_0 + data_1\n",
    "    labels = ['0'] * len(data_0) + ['1'] * len(data_1)\n",
    "    \n",
    "    # Plot\n",
    "    sns.boxplot(x=labels, y=data)\n",
    "    plt.title(f\"Distribution of {feature_name} by Label\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(feature_name)\n",
    "    plt.show()\n",
    "\n",
    "# Example visualization for 'num_communities' and 'modularity'\n",
    "plot_feature_distributions(features_by_label, \"num_communities\")\n",
    "plot_feature_distributions(features_by_label, \"modularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Separating the features based on the label\n",
    "features_0 = features_df[features_df['Label'] == 0].drop('Label', axis=1)\n",
    "features_1 = features_df[features_df['Label'] == 1].drop('Label', axis=1)\n",
    "\n",
    "# Define the feature names (excluding 'Label')\n",
    "feature_names = features_df.columns.drop('Label')\n",
    "\n",
    "# Print basic statistics for each feature\n",
    "for name in feature_names:\n",
    "    feature_0_stats = features_0[name].agg(['mean', 'median', 'std']).round(2)\n",
    "    feature_1_stats = features_1[name].agg(['mean', 'median', 'std']).round(2)\n",
    "    \n",
    "    print(f\"{name} - Label 0:\")\n",
    "    print(f\"  Mean: {feature_0_stats['mean']}, Median: {feature_0_stats['median']}, Std: {feature_0_stats['std']}\")\n",
    "    print(f\"{name} - Label 1:\")\n",
    "    print(f\"  Mean: {feature_1_stats['mean']}, Median: {feature_1_stats['median']}, Std: {feature_1_stats['std']}\\n\")\n",
    "\n",
    "# Visualization\n",
    "def plot_feature_distributions(features_df, feature_names):\n",
    "    \"\"\"Plot distributions of features by label.\"\"\"\n",
    "    for name in feature_names:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(features_df, x=name, hue=\"Label\", element=\"step\", stat=\"density\", common_norm=False, kde=True)\n",
    "        plt.title(f\"Distribution of {name} by Label\")\n",
    "        plt.xlabel(name)\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend(title='Label', labels=['0', '1'])\n",
    "        plt.show()\n",
    "\n",
    "plot_feature_distributions(features_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming BrainDataset and to_simple_graph are already defined\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Function to calculate NMI and ARI for all pairs of graphs\n",
    "def calculate_similarity_scores(partitions, labels):\n",
    "    n = len(partitions)\n",
    "    nmi_scores = np.zeros((n, n))\n",
    "    ari_scores = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            partition_i = partitions[i]\n",
    "            partition_j = partitions[j]\n",
    "            # Convert partitions to list of community labels for each node\n",
    "            labels_i = list(partition_i.values())\n",
    "            labels_j = list(partition_j.values())\n",
    "            nmi_scores[i, j] = normalized_mutual_info_score(labels_i, labels_j)\n",
    "            ari_scores[i, j] = adjusted_rand_score(labels_i, labels_j)\n",
    "\n",
    "    return nmi_scores, ari_scores\n",
    "\n",
    "# Example: Analyze similarity scores by label\n",
    "def analyze_scores_by_label(scores, labels):\n",
    "    same_label_scores = []\n",
    "    diff_label_scores = []\n",
    "    for i in range(len(scores)):\n",
    "        for j in range(i + 1, len(scores)):\n",
    "            if labels[i] == labels[j]:\n",
    "                same_label_scores.append(scores[i, j])\n",
    "            else:\n",
    "                diff_label_scores.append(scores[i, j])\n",
    "    return same_label_scores, diff_label_scores\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs\n",
    "nx_graphs = [to_simple_graph(graph) for graph in tqdm(graphs, desc=\"Converting graphs\")]\n",
    "\n",
    "# Apply Louvain method to each NetworkX graph to get partitions\n",
    "partitions = [community_louvain.best_partition(graph) for graph in tqdm(nx_graphs, desc=\"Applying Louvain\")]\n",
    "\n",
    "# Proceed with the similarity score calculations as before\n",
    "nmi_scores, ari_scores = calculate_similarity_scores(partitions, labels)\n",
    "nmi_same, nmi_diff = analyze_scores_by_label(nmi_scores, labels)\n",
    "ari_same, ari_diff = analyze_scores_by_label(ari_scores, labels)\n",
    "\n",
    "# Statistical tests and output\n",
    "t_stat_nmi, p_value_nmi = ttest_ind(nmi_same, nmi_diff)\n",
    "t_stat_ari, p_value_ari = ttest_ind(ari_same, ari_diff)\n",
    "\n",
    "print(f\"NMI - Same vs. Different Labels: T-stat = {t_stat_nmi:.3f}, P-value = {p_value_nmi:.3f}\")\n",
    "print(f\"ARI - Same vs. Different Labels: T-stat = {t_stat_ari:.3f}, P-value = {p_value_ari:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def calculate_cluster_averages(scores, labels, num_clusters=3):\n",
    "    \"\"\"Calculates cluster averages for NMI or ARI scores within each label.\"\"\"\n",
    "    averages = {'0': [], '1': []}\n",
    "    \n",
    "    for label in ['0', '1']:\n",
    "        # Extract scores for current label\n",
    "        label_indices = [i for i, l in enumerate(labels) if str(l) == label]\n",
    "        label_scores = scores[np.ix_(label_indices, label_indices)]\n",
    "        \n",
    "        # Calculate distance matrix (1 - score to treat it as 'distance')\n",
    "        distance_matrix = 1 - label_scores\n",
    "        \n",
    "        # Apply clustering that can handle a precomputed distance matrix\n",
    "        clustering = SpectralClustering(n_clusters=num_clusters, affinity='precomputed', random_state=42)\n",
    "        clusters = clustering.fit_predict(distance_matrix)\n",
    "        \n",
    "        # Calculate averages for each cluster\n",
    "        for cluster_id in range(num_clusters):\n",
    "            cluster_scores = label_scores[np.where(clusters == cluster_id)[0], :]\n",
    "            cluster_distances = 1 - cluster_scores  # Convert scores back to 'distances' for averaging\n",
    "            averages[label].append(np.mean(cluster_distances))\n",
    "    \n",
    "    return averages\n",
    "\n",
    "\n",
    "# Mock-up function call, adjust parameters as necessary\n",
    "averages = calculate_cluster_averages(nmi_scores, labels)\n",
    "print(\"Average NMI scores by cluster within labels:\", averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Exploration based on Girvan-Newman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating NMI and ARI scores for pairs of graphs and performing statistical tests to compare these scores between graph pairs with the same labels versus different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming BrainDataset and to_simple_graph are already defined\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs\n",
    "nx_graphs = [to_simple_graph(graph) for graph in tqdm(graphs, desc=\"Converting graphs\")]\n",
    "\n",
    "# Apply Louvain method to each NetworkX graph to get partitions\n",
    "partitions = [community_louvain.best_partition(graph) for graph in tqdm(nx_graphs, desc=\"Applying Louvain\")]\n",
    "\n",
    "# Proceed with the similarity score calculations as before\n",
    "nmi_scores, ari_scores = calculate_similarity_scores(partitions, labels)\n",
    "nmi_same, nmi_diff = analyze_scores_by_label(nmi_scores, labels)\n",
    "ari_same, ari_diff = analyze_scores_by_label(ari_scores, labels)\n",
    "\n",
    "# Statistical tests and output\n",
    "t_stat_nmi, p_value_nmi = ttest_ind(nmi_same, nmi_diff)\n",
    "t_stat_ari, p_value_ari = ttest_ind(ari_same, ari_diff)\n",
    "\n",
    "print(f\"NMI - Same vs. Different Labels: T-stat = {t_stat_nmi:.3f}, P-value = {p_value_nmi:.3f}\")\n",
    "print(f\"ARI - Same vs. Different Labels: T-stat = {t_stat_ari:.3f}, P-value = {p_value_ari:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def calculate_cluster_averages(scores, labels, num_clusters=3):\n",
    "    \"\"\"Calculates cluster averages for NMI or ARI scores within each label.\"\"\"\n",
    "    averages = {'0': [], '1': []}\n",
    "    \n",
    "    for label in ['0', '1']:\n",
    "        # Extract scores for current label\n",
    "        label_indices = [i for i, l in enumerate(labels) if str(l) == label]\n",
    "        label_scores = scores[np.ix_(label_indices, label_indices)]\n",
    "        \n",
    "        # Calculate distance matrix (1 - score to treat it as 'distance')\n",
    "        distance_matrix = 1 - label_scores\n",
    "        \n",
    "        # Apply clustering that can handle a precomputed distance matrix\n",
    "        clustering = SpectralClustering(n_clusters=num_clusters, affinity='precomputed', random_state=42)\n",
    "        clusters = clustering.fit_predict(distance_matrix)\n",
    "        \n",
    "        # Calculate averages for each cluster\n",
    "        for cluster_id in range(num_clusters):\n",
    "            cluster_scores = label_scores[np.where(clusters == cluster_id)[0], :]\n",
    "            cluster_distances = 1 - cluster_scores  # Convert scores back to 'distances' for averaging\n",
    "            averages[label].append(np.mean(cluster_distances))\n",
    "    \n",
    "    return averages\n",
    "\n",
    "# Mock-up function call, adjust parameters as necessary\n",
    "averages = calculate_cluster_averages(nmi_scores, labels)\n",
    "print(\"Average NMI scores by cluster within labels:\", averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge Density Within and Cohesion! (Louvain & Girwan Newman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Louvain method: Edge Density Within & Cohesion\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from community import community_louvain\n",
    "\n",
    "# Assuming BrainDataset and to_simple_graph are already defined\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Function to calculate edge density within communities\n",
    "def calculate_edge_density_within(graph, partition):\n",
    "    intra_edges = 0\n",
    "    total_possible_intra_edges = 0\n",
    "    for community in set(partition.values()):\n",
    "        nodes_in_community = [nodes for nodes in partition.keys() if partition[nodes] == community]\n",
    "        subgraph = graph.subgraph(nodes_in_community)\n",
    "        intra_edges += subgraph.number_of_edges()\n",
    "        total_possible_intra_edges += len(nodes_in_community) * (len(nodes_in_community) - 1) / 2\n",
    "    return intra_edges / total_possible_intra_edges if total_possible_intra_edges else 0\n",
    "\n",
    "# Function to calculate cohesion\n",
    "def calculate_cohesion(graph, partition):\n",
    "    return nx.average_clustering(graph, nodes=partition.keys(), weight='weight')\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(graphs, labels):\n",
    "    features = {'Average Edge Density Within': [], 'Cohesion': [], 'Label': labels}\n",
    "    for graph in graphs:\n",
    "        nx_graph = to_simple_graph(graph)  # Convert DGLGraph to NetworkX graph\n",
    "        partition = community_louvain.best_partition(nx_graph)\n",
    "        features['Average Edge Density Within'].append(calculate_edge_density_within(nx_graph, partition))\n",
    "        features['Cohesion'].append(calculate_cohesion(nx_graph, partition))\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Calculate the features\n",
    "features_df = extract_features(graphs, labels)\n",
    "\n",
    "# Perform t-tests\n",
    "for feature in ['Average Edge Density Within', 'Cohesion']:\n",
    "    stat, p = ttest_ind(\n",
    "        features_df[features_df['Label'] == 0][feature],\n",
    "        features_df[features_df['Label'] == 1][feature]\n",
    "    )\n",
    "    print(f\"{feature} T-test: stat = {stat:.4f}, p = {p:.4f}\")\n",
    "\n",
    "# Visualization and statistics printing\n",
    "def plot_and_print_features(features_df, feature_names):\n",
    "    for name in feature_names:\n",
    "        feature_0 = features_df[features_df['Label'] == 0][name]\n",
    "        feature_1 = features_df[features_df['Label'] == 1][name]\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Label 0 - Mean: {np.mean(feature_0):.2f}, Median: {np.median(feature_0):.2f}, Std: {np.std(feature_0):.2f}\")\n",
    "        print(f\"  Label 1 - Mean: {np.mean(feature_1):.2f}, Median: {np.median(feature_1):.2f}, Std: {np.std(feature_1):.2f}\")\n",
    "        \n",
    "        # Plot distributions\n",
    "        sns.histplot(feature_0, color=\"skyblue\", label='Label 0', kde=True, stat=\"density\", linewidth=0)\n",
    "        sns.histplot(feature_1, color=\"red\", label='Label 1', kde=True, stat=\"density\", linewidth=0)\n",
    "        plt.title(name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Execute the visualization and statistics printing function\n",
    "plot_and_print_features(features_df, ['Average Edge Density Within', 'Cohesion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Girvan-Newman method: Edge Density Within & Cohesion\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from community import community_louvain\n",
    "\n",
    "# Assuming BrainDataset and to_simple_graph are already defined\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Function to calculate edge density within communities\n",
    "def calculate_edge_density_within(graph, partition):\n",
    "    intra_edges = 0\n",
    "    total_possible_intra_edges = 0\n",
    "    for community in set(partition.values()):\n",
    "        nodes_in_community = [nodes for nodes in partition.keys() if partition[nodes] == community]\n",
    "        subgraph = graph.subgraph(nodes_in_community)\n",
    "        intra_edges += subgraph.number_of_edges()\n",
    "        total_possible_intra_edges += len(nodes_in_community) * (len(nodes_in_community) - 1) / 2\n",
    "    return intra_edges / total_possible_intra_edges if total_possible_intra_edges else 0\n",
    "\n",
    "# Function to calculate cohesion\n",
    "def calculate_cohesion(graph, partition):\n",
    "    return nx.average_clustering(graph, nodes=partition.keys(), weight='weight')\n",
    "\n",
    "# Function to apply the Girvan-Newman method and extract the top-level partition\n",
    "def apply_girvan_newman(graph):\n",
    "    communities_generator = girvan_newman(graph)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    partition = {node: i for i, community in enumerate(top_level_communities) for node in community}\n",
    "    return partition\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(graphs, labels):\n",
    "    features = {'Average Edge Density Within': [], 'Cohesion': [], 'Label': labels}\n",
    "    for graph in graphs:\n",
    "        nx_graph = to_simple_graph(graph)  # Convert DGLGraph to NetworkX graph\n",
    "        partition = apply_girvan_newman(nx_graph)\n",
    "        features['Average Edge Density Within'].append(calculate_edge_density_within(nx_graph, partition))\n",
    "        features['Cohesion'].append(calculate_cohesion(nx_graph, partition))\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Calculate the features\n",
    "features_df = extract_features(graphs, labels)\n",
    "\n",
    "# Perform t-tests\n",
    "for feature in ['Average Edge Density Within', 'Cohesion']:\n",
    "    stat, p = ttest_ind(\n",
    "        features_df[features_df['Label'] == 0][feature],\n",
    "        features_df[features_df['Label'] == 1][feature]\n",
    "    )\n",
    "    print(f\"{feature} T-test: stat = {stat:.4f}, p = {p:.4f}\")\n",
    "\n",
    "# Visualization and statistics printing\n",
    "def plot_and_print_features(features_df, feature_names):\n",
    "    for name in feature_names:\n",
    "        feature_0 = features_df[features_df['Label'] == 0][name]\n",
    "        feature_1 = features_df[features_df['Label'] == 1][name]\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Label 0 - Mean: {np.mean(feature_0):.2f}, Median: {np.median(feature_0):.2f}, Std: {np.std(feature_0):.2f}\")\n",
    "        print(f\"  Label 1 - Mean: {np.mean(feature_1):.2f}, Median: {np.median(feature_1):.2f}, Std: {np.std(feature_1):.2f}\")\n",
    "        \n",
    "        # Plot distributions\n",
    "        sns.histplot(feature_0, color=\"skyblue\", label='Label 0', kde=True, stat=\"density\", linewidth=0)\n",
    "        sns.histplot(feature_1, color=\"red\", label='Label 1', kde=True, stat=\"density\", linewidth=0)\n",
    "        plt.title(name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Execute the visualization and statistics printing function\n",
    "plot_and_print_features(features_df, ['Average Edge Density Within', 'Cohesion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercommunity connectivity: How many edges connect different communities and how does this compare between labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\" Converts a DGL graph to a simplified NetworkX graph. \"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs\n",
    "nx_graphs = [to_simple_graph(g) for g in tqdm(graphs, desc=\"Converting DGLGraphs to NetworkX\")]\n",
    "\n",
    "def detect_communities_louvain(nx_graph):\n",
    "    partition = community_louvain.best_partition(nx_graph)\n",
    "    return partition\n",
    "\n",
    "def classify_edges(nx_graph, partition):\n",
    "    intra_community_edges = 0\n",
    "    inter_community_edges = 0\n",
    "    \n",
    "    for edge in nx_graph.edges():\n",
    "        if partition[edge[0]] == partition[edge[1]]:\n",
    "            intra_community_edges += 1\n",
    "        else:\n",
    "            inter_community_edges += 1\n",
    "            \n",
    "    return intra_community_edges, inter_community_edges\n",
    "\n",
    "# Detect communities and classify edges for each graph\n",
    "edges_data = {'Label': [], 'IntraCommunityEdges': [], 'InterCommunityEdges': []}\n",
    "\n",
    "for nx_graph, label in tqdm(zip(nx_graphs, labels), total=len(labels), desc=\"Detecting communities and classifying edges\"):\n",
    "    partition = detect_communities_louvain(nx_graph)\n",
    "    intra_edges, inter_edges = classify_edges(nx_graph, partition)\n",
    "    edges_data['Label'].append(label)\n",
    "    edges_data['IntraCommunityEdges'].append(intra_edges)\n",
    "    edges_data['InterCommunityEdges'].append(inter_edges)\n",
    "\n",
    "edges_df = pd.DataFrame(edges_data)\n",
    "\n",
    "# Perform t-tests to compare edge counts between labels\n",
    "intra_t_stat, intra_p_value = ttest_ind(\n",
    "    edges_df[edges_df['Label'] == 0]['IntraCommunityEdges'],\n",
    "    edges_df[edges_df['Label'] == 1]['IntraCommunityEdges']\n",
    ")\n",
    "\n",
    "inter_t_stat, inter_p_value = ttest_ind(\n",
    "    edges_df[edges_df['Label'] == 0]['InterCommunityEdges'],\n",
    "    edges_df[edges_df['Label'] == 1]['InterCommunityEdges']\n",
    ")\n",
    "\n",
    "print(f\"Intra-Community Edges - T-statistic: {intra_t_stat}, P-value: {intra_p_value}\")\n",
    "print(f\"Inter-Community Edges - T-statistic: {inter_t_stat}, P-value: {inter_p_value}\")\n",
    "\n",
    "# Visualization\n",
    "sns.histplot(data=edges_df, x='IntraCommunityEdges', hue='Label', element='step', stat='density', common_norm=False)\n",
    "plt.title('Intra-Community Edge Counts by Label')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=edges_df, x='InterCommunityEdges', hue='Label', element='step', stat='density', common_norm=False)\n",
    "plt.title('Inter-Community Edge Counts by Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motifs: Motifs are small, recurring subgraphs that represent common structural patterns within a larger network. Commonly analyzed motifs include stars, chains, triangles, squares, and cliques of various sizes. Each motif can reveal different aspects of the local topology of the network. For instance, in brain networks, certain motifs might be overrepresented in individuals with specific conditions or atypical neurological patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming BrainDataset and to_simple_graph are already defined\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Function to convert DGLGraph to NetworkX graph\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "# Assuming 'graphs' is your list of DGLGraph objects and 'labels' is your list of labels\n",
    "nx_graphs = [to_simple_graph(g) for g in graphs]  # Convert to simple NetworkX graphs\n",
    "\n",
    "# Define a function to find all subgraphs of a certain size (motif size) in a given graph\n",
    "def find_subgraphs(graph, motif_size):\n",
    "    for nodes in combinations(graph.nodes(), motif_size):\n",
    "        subgraph = graph.subgraph(nodes)\n",
    "        if nx.is_connected(subgraph):\n",
    "            yield subgraph\n",
    "\n",
    "# Define motifs as NetworkX graphs\n",
    "motifs = {\n",
    "    'triangle': nx.Graph([(0, 1), (1, 2), (2, 0)]),\n",
    "    'star': nx.star_graph(3),\n",
    "    'square': nx.cycle_graph(4)\n",
    "}\n",
    "\n",
    "# Define a function to count the occurrences of a given motif in a graph\n",
    "def count_motif_occurrences(graph, motif):\n",
    "    motif_count = 0\n",
    "    for subgraph in find_subgraphs(graph, len(motif.nodes())):\n",
    "        if nx.is_isomorphic(subgraph, motif):\n",
    "            motif_count += 1\n",
    "    return motif_count\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs\n",
    "nx_graphs = [to_simple_graph(g) for g in tqdm(graphs, desc=\"Converting graphs\")]\n",
    "\n",
    "# Initialize motif count storage\n",
    "motif_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over graphs and count motifs\n",
    "for graph, label in tqdm(zip(nx_graphs, labels), total=len(labels), desc=\"Counting motifs\"):\n",
    "    for motif_name, motif_graph in motifs.items():\n",
    "        count = count_motif_occurrences(graph, motif_graph)\n",
    "        motif_counts[motif_name][label] += count\n",
    "\n",
    "# Perform t-tests and visualize distributions\n",
    "for motif_name, counts in motif_counts.items():\n",
    "    labels_0 = counts[0]\n",
    "    labels_1 = counts[1]\n",
    "    t_stat, p_value = ttest_ind(labels_0, labels_1)\n",
    "    print(f\"Motif {motif_name}: t-statistic={t_stat}, p-value={p_value}\")\n",
    "\n",
    "    plt.figure()\n",
    "    sns.histplot(labels_0, color='blue', label='Label 0', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(labels_1, color='red', label='Label 1', kde=True, stat=\"density\", linewidth=0)\n",
    "    plt.legend()\n",
    "    plt.title(f\"{motif_name} motif count distribution\")\n",
    "    plt.xlabel('Motif Count')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small worldness: The small-worldness coefficient (sigma) can be calculated as the ratio of the clustering coefficient of the graph to the clustering coefficient of an equivalent random graph, divided by the ratio of the average shortest path length of the graph to the average shortest path length of an equivalent random graph. A graph is considered a small-world if this ratio is greater than 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def to_simple_graph(dgl_graph):\n",
    "    \"\"\"Converts a DGL graph to a simplified NetworkX graph.\"\"\"\n",
    "    g = dgl.to_networkx(dgl_graph).to_undirected()\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "def calculate_small_worldness(graph):\n",
    "    \"\"\"Calculates the small-worldness of a given graph.\"\"\"\n",
    "    # Clustering coefficient of the graph\n",
    "    clustering_coeff = nx.average_clustering(graph)\n",
    "    # Average shortest path length\n",
    "    if nx.is_connected(graph):\n",
    "        avg_shortest_path_length = nx.average_shortest_path_length(graph)\n",
    "    else:\n",
    "        # For unconnected graphs, we cannot calculate the average shortest path length directly\n",
    "        avg_shortest_path_length = np.nan\n",
    "    \n",
    "    # Generating an equivalent random graph\n",
    "    random_graph = nx.gnm_random_graph(n=graph.number_of_nodes(), m=graph.number_of_edges())\n",
    "    random_clustering_coeff = nx.average_clustering(random_graph)\n",
    "    if nx.is_connected(random_graph):\n",
    "        random_avg_shortest_path_length = nx.average_shortest_path_length(random_graph)\n",
    "    else:\n",
    "        # Rare case, but we handle it\n",
    "        random_avg_shortest_path_length = np.nan\n",
    "    \n",
    "    # Small-worldness coefficient (sigma)\n",
    "    if random_clustering_coeff > 0 and random_avg_shortest_path_length > 0:\n",
    "        sigma = (clustering_coeff / random_clustering_coeff) / (avg_shortest_path_length / random_avg_shortest_path_length)\n",
    "    else:\n",
    "        sigma = np.nan\n",
    "    return sigma\n",
    "\n",
    "# Load your dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Convert DGLGraphs to NetworkX graphs and calculate small-worldness\n",
    "small_worldness_values = []\n",
    "for graph in tqdm(graphs, desc=\"Calculating small-worldness\"):\n",
    "    nx_graph = to_simple_graph(graph)\n",
    "    sigma = calculate_small_worldness(nx_graph)\n",
    "    small_worldness_values.append(sigma)\n",
    "\n",
    "# Prepare data for analysis\n",
    "data = {'SmallWorldness': small_worldness_values, 'Label': labels}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform t-tests between labels\n",
    "t_stat, p_value = ttest_ind(\n",
    "    df[df['Label'] == 0]['SmallWorldness'].dropna(),\n",
    "    df[df['Label'] == 1]['SmallWorldness'].dropna()\n",
    ")\n",
    "print(f\"Small-Worldness - T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# Visualization of the distributions of small-worldness\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df, x='SmallWorldness', hue='Label', element='step', stat='density', common_norm=False)\n",
    "plt.title('Small-Worldness across Labels')\n",
    "plt.xlabel('Small-Worldness (Sigma)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv, AvgPooling, MaxPooling\n",
    "import logging\n",
    "from scipy.stats import t\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    MLP Layer used after graph vector representation\n",
    "\"\"\"\n",
    "\n",
    "class MLPReadout(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, L=2): #L=nb_hidden_layers\n",
    "        super().__init__()\n",
    "        list_FC_layers = [nn.Linear(input_dim//2**l, input_dim//2**(l+1) , bias=True) for l in range(L)]\n",
    "        list_FC_layers.append(nn.Linear(input_dim//2**L, output_dim, bias=True))\n",
    "        self.FC_layers = nn.ModuleList(list_FC_layers)\n",
    "        self.L = L\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for l in range(self.L):\n",
    "            y = self.FC_layers[l](y)\n",
    "            y = F.relu(y)\n",
    "        y = self.FC_layers[self.L](y)\n",
    "        return y\n",
    "    \n",
    "class Norm(nn.Module):\n",
    "\n",
    "    def __init__(self, norm_type, hidden_dim=64, print_info=None):\n",
    "        super(Norm, self).__init__()\n",
    "        # assert norm_type in ['bn', 'ln', 'gn', None]\n",
    "        self.norm = None\n",
    "        self.print_info = print_info\n",
    "        if norm_type == 'bn':\n",
    "            self.norm = nn.BatchNorm1d(hidden_dim)\n",
    "        elif norm_type == 'gn':\n",
    "            self.norm = norm_type\n",
    "            self.weight = nn.Parameter(torch.ones(hidden_dim))\n",
    "            self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "            self.mean_scale = nn.Parameter(torch.ones(hidden_dim))\n",
    "\n",
    "    def forward(self, graph, tensor, print_=False):\n",
    "        if self.norm is not None and type(self.norm) != str:\n",
    "            return self.norm(tensor)\n",
    "        elif self.norm is None:\n",
    "            return tensor\n",
    "\n",
    "        batch_list = graph.batch_num_nodes()\n",
    "        batch_size = len(batch_list)\n",
    "        batch_list = torch.tensor(batch_list, dtype=torch.long).to(tensor.device)\n",
    "        batch_index = torch.arange(batch_size).to(tensor.device).repeat_interleave(batch_list)\n",
    "        batch_index = batch_index.view((-1,) + (1,) * (tensor.dim() - 1)).expand_as(tensor)\n",
    "        mean = torch.zeros(batch_size, *tensor.shape[1:]).to(tensor.device)\n",
    "        mean = mean.scatter_add_(0, batch_index, tensor)\n",
    "        mean = (mean.T / batch_list).T\n",
    "        mean = mean.repeat_interleave(batch_list, dim=0)\n",
    "\n",
    "        sub = tensor - mean * self.mean_scale\n",
    "\n",
    "        std = torch.zeros(batch_size, *tensor.shape[1:]).to(tensor.device)\n",
    "        std = std.scatter_add_(0, batch_index, sub.pow(2))\n",
    "        std = ((std.T / batch_list).T + 1e-6).sqrt()\n",
    "        std = std.repeat_interleave(batch_list, dim=0)\n",
    "        return self.weight * sub / std + self.bias\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    GCN: Graph Convolutional Networks\n",
    "    Thomas N. Kipf, Max Welling, Semi-Supervised Classification with Graph Convolutional Networks (ICLR 2017)\n",
    "    http://arxiv.org/abs/1609.02907\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class NodeApplyModule(nn.Module):\n",
    "    # Update node feature h_v with (Wh_v+b)\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        \n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        return {'h': h}\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "        Param: [in_dim, out_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, activation, dropout, batch_norm, residual=False, dgl_builtin=False, e_feat=False):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_dim\n",
    "        self.out_channels = out_dim\n",
    "        self.batch_norm = batch_norm\n",
    "        self.residual = residual\n",
    "        self.dgl_builtin = dgl_builtin\n",
    "        \n",
    "        if in_dim != out_dim:\n",
    "            self.residual = False\n",
    "\n",
    "        # self.batchnorm_h = nn.BatchNorm1d(out_dim)\n",
    "        # self.batchnorm_e = nn.BatchNorm1d(out_dim)\n",
    "        self.batchnorm_h = Norm('bn', out_dim)\n",
    "        # if e_feat:\n",
    "        self.batchnorm_e = Norm('bn', out_dim)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if self.dgl_builtin == False:\n",
    "            self.apply_mod = NodeApplyModule(in_dim, out_dim)\n",
    "        elif dgl.__version__ < \"0.5\":\n",
    "            self.conv = GraphConv(in_dim, out_dim)\n",
    "        else:\n",
    "            self.conv = GraphConv(in_dim, out_dim, allow_zero_in_degree=True)\n",
    "\n",
    "        # Sends a message of node feature h\n",
    "        # Equivalent to => return {'m': edges.src['h']}\n",
    "        self.message_func = fn.copy_u(u='h', out='m') # if not e_feat else fn.u_mul_e('h', 'e', 'm')\n",
    "        self.reduce_func = fn.mean('m', 'h')\n",
    "\n",
    "    # def forward(self, g, feature):\n",
    "    #     h_in = feature   # to be used for residual connection\n",
    "    #\n",
    "    #     if self.dgl_builtin == False:\n",
    "    #         g.ndata['h'] = feature\n",
    "    #         g.update_all(self.message_func, self.reduce_func)\n",
    "    #         g.apply_nodes(func=self.apply_mod)\n",
    "    #         h = g.ndata['h'] # result of graph convolution\n",
    "    #     else:\n",
    "    #         h = self.conv(g, feature)\n",
    "    #\n",
    "    #     if self.batch_norm:\n",
    "    #         h = self.batchnorm_h(h) # batch normalization\n",
    "    #\n",
    "    #     if self.activation:\n",
    "    #         h = self.activation(h)\n",
    "    #\n",
    "    #     if self.residual:\n",
    "    #         h = h_in + h # residual connection\n",
    "    #\n",
    "    #     h = self.dropout(h)\n",
    "    #     return h\n",
    "        \n",
    "    def forward(self, g, feature):\n",
    "        h_in = feature   # to be used for residual connection\n",
    "        # e_in = e\n",
    "\n",
    "        if self.dgl_builtin == False:\n",
    "            g.ndata['h'] = feature\n",
    "            # g.edata['e'] = e\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            g.apply_nodes(func=self.apply_mod)\n",
    "            h = g.ndata['h'] # result of graph convolution\n",
    "            # e = g.edata['e']\n",
    "        else:\n",
    "            h = self.conv(g, feature)\n",
    "\n",
    "        if self.batch_norm:\n",
    "            h = self.batchnorm_h(g, h) # batch normalization\n",
    "            # e = self.batchnorm_e(g, e) # batch normalization\n",
    "       \n",
    "        if self.activation:\n",
    "            h = self.activation(h)\n",
    "            # e = self.activation(e)\n",
    "        \n",
    "        if self.residual:\n",
    "            h = h_in + h # residual connection\n",
    "            # e = e_in + e\n",
    "            \n",
    "        h = self.dropout(h)\n",
    "        # e = self.dropout(e)\n",
    "        return h\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}(in_channels={}, out_channels={}, residual={})'.format(self.__class__.__name__,\n",
    "                                             self.in_channels,\n",
    "                                             self.out_channels, self.residual)\n",
    "\n",
    "\n",
    "\n",
    "class SAGPool(torch.nn.Module):\n",
    "    \"\"\"The Self-Attention Pooling layer in paper\n",
    "    `Self Attention Graph Pooling <https://arxiv.org/pdf/1904.08082.pdf>`\n",
    "\n",
    "    Args:\n",
    "        in_dim (int): The dimension of node feature.\n",
    "        ratio (float, optional): The pool ratio which determines the amount of nodes\n",
    "            remain after pooling. (default: :obj:`0.5`)\n",
    "        conv_op (torch.nn.Module, optional): The graph convolution layer in dgl used to\n",
    "        compute scale for each node. (default: :obj:`dgl.nn.GraphConv`)\n",
    "        non_linearity (Callable, optional): The non-linearity function, a pytorch function.\n",
    "            (default: :obj:`torch.tanh`)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim:int, ratio=0.5, non_linearity=torch.tanh):\n",
    "        super(SAGPool, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.ratio = ratio\n",
    "        if dgl.__version__ < \"0.5\":\n",
    "            self.score_layer = GraphConv(in_dim, 1)\n",
    "        else:\n",
    "            self.score_layer = GraphConv(in_dim, 1, allow_zero_in_degree=True)\n",
    "        self.non_linearity = non_linearity\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, graph:dgl.DGLGraph, feature:torch.Tensor, e_feat=None):\n",
    "        score = self.score_layer(graph, feature).squeeze()\n",
    "        perm, next_batch_num_nodes = TopKPooling(score, self.ratio, get_batch_id(graph.batch_num_nodes()), graph.batch_num_nodes())\n",
    "        feature = feature[perm] * self.non_linearity(score[perm]).view(-1, 1)\n",
    "        graph = dgl.node_subgraph(graph, perm)\n",
    "\n",
    "        # node_subgraph currently does not support batch-graph,\n",
    "        # the 'batch_num_nodes' of the result subgraph is None.\n",
    "        # So we manually set the 'batch_num_nodes' here.\n",
    "        # Since global pooling has nothing to do with 'batch_num_edges',\n",
    "        # we can leave it to be None or unchanged.\n",
    "        graph.set_batch_num_nodes(next_batch_num_nodes)\n",
    "\n",
    "        score = self.softmax(score)\n",
    "        if torch.nonzero(torch.isnan(score)).size(0) > 0:\n",
    "            print(score[torch.nonzero(torch.isnan(score))])\n",
    "            raise KeyError\n",
    "\n",
    "        if e_feat is not None:\n",
    "            e_feat = graph.edata['feat'].unsqueeze(-1)\n",
    "\n",
    "        return graph, feature, perm, score, e_feat\n",
    "\n",
    "\n",
    "class SAGPoolBlock(torch.nn.Module):\n",
    "    \"\"\"A combination of GCN layer and SAGPool layer,\n",
    "    followed by a concatenated (mean||sum) readout operation.\n",
    "    return the graph embedding with the same dimension of node embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim:int, pool_ratio=0.5):\n",
    "        super(SAGPoolBlock, self).__init__()\n",
    "        self.pool = SAGPool(in_dim, ratio=pool_ratio)\n",
    "        self.avgpool = AvgPooling()\n",
    "        self.maxpool = MaxPooling()\n",
    "        self.mlp = torch.nn.Linear(in_dim * 2, in_dim)\n",
    "\n",
    "    def forward(self, graph, feature):\n",
    "        graph, out, _, _, _ = self.pool(graph, feature)\n",
    "        g_out = torch.cat([self.avgpool(graph, out), self.maxpool(graph, out)], dim=-1)\n",
    "        g_out = F.relu(self.mlp(g_out))\n",
    "        return graph, out, g_out\n",
    "\n",
    "\n",
    "class SAGPoolReadout(torch.nn.Module):\n",
    "    \"\"\"A combination of GCN layer and SAGPool layer,\n",
    "    followed by a concatenated (mean||sum) readout operation.\n",
    "    \"\"\"\n",
    "    def __init__(self, net_params, pool_ratio=0.5, pool=True):\n",
    "        super(SAGPoolReadout, self).__init__()\n",
    "        in_dim = net_params['in_dim']\n",
    "        out_dim = net_params['out_dim']\n",
    "        dropout = net_params['dropout']\n",
    "        n_classes = net_params['n_classes']\n",
    "        self.batch_norm = net_params['batch_norm']\n",
    "        self.residual = net_params['residual']\n",
    "        self.e_feat = net_params['edge_feat']\n",
    "        self.conv = GCNLayer(in_dim, out_dim, F.relu, dropout, self.batch_norm, self.residual, e_feat=self.e_feat)\n",
    "        self.use_pool = pool\n",
    "        self.pool = SAGPool(out_dim, ratio=pool_ratio)\n",
    "        self.avgpool = AvgPooling()\n",
    "        self.maxpool = MaxPooling()\n",
    "        self.MLP_layer = MLPReadout(out_dim * 2, n_classes)\n",
    "\n",
    "    def forward(self, graph, feature, e_feat=None):\n",
    "        out, e_feat = self.conv(graph, feature, e_feat)\n",
    "        if self.use_pool:\n",
    "            graph, out, _, _, e_feat = self.pool(graph, out, e_feat)\n",
    "        hg = torch.cat([self.avgpool(graph, out), self.maxpool(graph, out)], dim=-1)\n",
    "        scores = self.MLP_layer(hg)\n",
    "        return scores\n",
    "\n",
    "    def loss(self, pred, label, cluster=False):\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "def get_batch_id(num_nodes:torch.Tensor):\n",
    "    \"\"\"Convert the num_nodes array obtained from batch graph to batch_id array\n",
    "    for each node.\n",
    "\n",
    "    Args:\n",
    "        num_nodes (torch.Tensor): The tensor whose element is the number of nodes\n",
    "            in each graph in the batch graph.\n",
    "    \"\"\"\n",
    "    batch_size = num_nodes.size(0)\n",
    "    batch_ids = []\n",
    "    for i in range(batch_size):\n",
    "        item = torch.full((num_nodes[i],), i, dtype=torch.long, device=num_nodes.device)\n",
    "        batch_ids.append(item)\n",
    "    return torch.cat(batch_ids)\n",
    "\n",
    "\n",
    "def TopKPooling(x:torch.Tensor, ratio:float, batch_id:torch.Tensor, num_nodes:torch.Tensor):\n",
    "    \"\"\"The top-k pooling method. Given a graph batch, this method will pool out some\n",
    "    nodes from input node feature tensor for each graph according to the given ratio.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): The input node feature batch-tensor to be pooled.\n",
    "        ratio (float): the pool ratio. For example if :obj:`ratio=0.5` then half of the input\n",
    "            tensor will be pooled out.\n",
    "        batch_id (torch.Tensor): The batch_id of each element in the input tensor.\n",
    "        num_nodes (torch.Tensor): The number of nodes of each graph in batch.\n",
    "    \n",
    "    Returns:\n",
    "        perm (torch.Tensor): The index in batch to be kept.\n",
    "        k (torch.Tensor): The remaining number of nodes for each graph.\n",
    "    \"\"\"\n",
    "    batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n",
    "\n",
    "    cum_num_nodes = torch.cat(\n",
    "        [num_nodes.new_zeros(1),\n",
    "         num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
    "\n",
    "    index = torch.arange(batch_id.size(0), dtype=torch.long, device=x.device)\n",
    "    index = (index - cum_num_nodes[batch_id]) + (batch_id * max_num_nodes)\n",
    "\n",
    "    dense_x = x.new_full((batch_size * max_num_nodes, ), torch.finfo(x.dtype).min)\n",
    "    dense_x[index] = x\n",
    "    dense_x = dense_x.view(batch_size, max_num_nodes)\n",
    "\n",
    "    _, perm = dense_x.sort(dim=-1, descending=True)\n",
    "    perm = perm + cum_num_nodes.view(-1, 1)\n",
    "    perm = perm.view(-1)\n",
    "\n",
    "    k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n",
    "    mask = [\n",
    "        torch.arange(k[i], dtype=torch.long, device=x.device) +\n",
    "        i * max_num_nodes for i in range(batch_size)]\n",
    "\n",
    "    mask = torch.cat(mask, dim=0)\n",
    "    perm = perm[mask]\n",
    "\n",
    "    return perm, k\n",
    "\n",
    "def reset_graph_features(batched_graph):\n",
    "    # Example: Reset or initialize 'feat' for each node in the batched graph\n",
    "    # This is a placeholder; adjust according to your actual data and requirements\n",
    "    num_nodes = batched_graph.number_of_nodes()\n",
    "    feat_dim = batched_graph.ndata['feat'].shape[1]  # Assuming 'feat' is already set and you're resetting it\n",
    "    batched_graph.ndata['feat'] = torch.zeros((num_nodes, feat_dim))\n",
    "    return batched_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, n_classes, dropout_rates):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        prev_dim = in_dim\n",
    "        \n",
    "        for hidden_dim, dropout_rate in zip(hidden_dims, dropout_rates):\n",
    "            self.layers.append(dgl.nn.GraphConv(prev_dim, hidden_dim, activation=F.relu))\n",
    "            self.dropouts.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "            \n",
    "        # Final classifier layer\n",
    "        self.classifier = nn.Linear(prev_dim, n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        h = g.ndata['feat']  # Assuming 'feat' is the node feature name\n",
    "        for layer, dropout in zip(self.layers, self.dropouts):\n",
    "            h = layer(g, h)\n",
    "            h = dropout(h)\n",
    "            \n",
    "        g.ndata['h'] = h\n",
    "        hg = dgl.mean_nodes(g, 'h')  # Graph-level representation\n",
    "        \n",
    "        return self.classifier(hg)\n",
    "    \n",
    "    \n",
    "def custom_collate_fn(batch):\n",
    "    graphs, labels = map(list, zip(*batch))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    batched_graph = reset_graph_features(batched_graph)  # Ensure consistent schema\n",
    "    labels = torch.tensor(labels)\n",
    "    return batched_graph, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Model - Plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset:  Abide100Dataset\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc3437a938849edb88592632c91d3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.1946s\n",
      "Epoch 1, Train Loss: 0.6927806943655014, Val Loss: 0.6900881443704877\n",
      "Validation loss decreased (inf --> 0.690088). Saving model ...\n",
      "Epoch 2, Train Loss: 0.6850884079933166, Val Loss: 0.6916479383196149\n",
      "Epoch 3, Train Loss: 0.6782233834266662, Val Loss: 0.6741883669580732\n",
      "Validation loss decreased (0.690088 --> 0.674188). Saving model ...\n",
      "Epoch 4, Train Loss: 0.6743899643421173, Val Loss: 0.6720784391675677\n",
      "Validation loss decreased (0.674188 --> 0.672078). Saving model ...\n",
      "Epoch 5, Train Loss: 0.6640249937772751, Val Loss: 0.6811853987830025\n",
      "Epoch 6, Train Loss: 0.6431253045797348, Val Loss: 0.6717875940459115\n",
      "Validation loss decreased (0.672078 --> 0.671788). Saving model ...\n",
      "Epoch 7, Train Loss: 0.633242005109787, Val Loss: 0.6746531469481332\n",
      "Epoch 8, Train Loss: 0.6141926363110543, Val Loss: 0.6623421226228986\n",
      "Validation loss decreased (0.671788 --> 0.662342). Saving model ...\n",
      "Epoch 9, Train Loss: 0.606012937426567, Val Loss: 0.7227551681654794\n",
      "Epoch 10, Train Loss: 0.6004922777414322, Val Loss: 0.6690721596990313\n",
      "Epoch 11, Train Loss: 0.5513682395219803, Val Loss: 0.658237133707319\n",
      "Validation loss decreased (0.662342 --> 0.658237). Saving model ...\n",
      "Epoch 12, Train Loss: 0.5345040917396545, Val Loss: 0.6997948033469064\n",
      "Epoch 13, Train Loss: 0.5272233113646507, Val Loss: 0.69394793680736\n",
      "Epoch 14, Train Loss: 0.5280264183878899, Val Loss: 0.6755889398711068\n",
      "Epoch 15, Train Loss: 0.500480879843235, Val Loss: 0.6815037855080196\n",
      "Epoch 16, Train Loss: 0.48259741216897967, Val Loss: 0.6749403391565595\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.624390243902439\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming BrainDataset, GCNModel, and all necessary functions are defined above\n",
    "\n",
    "# Add to your existing imports\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Early stopping criteria parameters\n",
    "patience = 5\n",
    "min_delta = 0.001\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopper = EarlyStopping(patience=patience, min_delta=min_delta)\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graphs, labels):\n",
    "        self.graphs = graphs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    graphs, labels = map(list, zip(*batch))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.tensor(labels)\n",
    "    return batched_graph, labels\n",
    "\n",
    "# Load the dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "indices = list(range(len(graphs)))\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_indices, temp_indices, train_labels, temp_labels = train_test_split(indices, labels, test_size=0.4, random_state=42)\n",
    "val_indices, test_indices, val_labels, test_labels = train_test_split(temp_indices, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Prepare the datasets\n",
    "train_graphs = [graphs[i] for i in train_indices]\n",
    "val_graphs = [graphs[i] for i in val_indices]\n",
    "test_graphs = [graphs[i] for i in test_indices]\n",
    "\n",
    "train_labels = [labels[i] for i in train_indices]\n",
    "val_labels = [labels[i] for i in val_indices]\n",
    "test_labels = [labels[i] for i in test_indices]\n",
    "\n",
    "train_dataset = GraphDataset(train_graphs, train_labels)\n",
    "val_dataset = GraphDataset(val_graphs, val_labels)\n",
    "test_dataset = GraphDataset(test_graphs, test_labels)\n",
    "\n",
    "# Prepare the DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Adjust model initialization with increased complexity\n",
    "model = GCNModel(\n",
    "    in_dim=Abide100.node_feat_dim, \n",
    "    hidden_dims=[256, 256, 128, 128],  # Increased model complexity\n",
    "    n_classes=2,\n",
    "    dropout_rates=[0.5, 0.5, 0.5],  # Added dropout to an additional layer\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "early_stopper = EarlyStopping(patience=5, min_delta=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005) \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "val_loss_min = np.Inf \n",
    "\n",
    "# Training Loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        logits = model(batched_graph)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, labels in val_dataloader:\n",
    "            logits = model(batched_graph)\n",
    "            val_loss += loss_fn(logits, labels).item()\n",
    "    \n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_dataloader)}, Val Loss: {val_loss}\")\n",
    "\n",
    "    if val_loss < val_loss_min:\n",
    "        print(f'Validation loss decreased ({val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
    "        val_loss_min = val_loss\n",
    "    \n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    scheduler.step(val_loss)  # Learning rate scheduler step\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        logits = model(batched_graph)\n",
    "        probabilities = torch.softmax(logits, dim=1)[:, 1]\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predictions.extend(probabilities.numpy())\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calculate accuracy\n",
    "predicted_labels = np.round(all_predictions)\n",
    "accuracy = accuracy_score(all_labels, predicted_labels)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Model - Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, n_classes, dropout_rates, activations, extra_feat_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            GCNLayer(in_dim if i == 0 else hidden_dims[i - 1], hidden_dims[i], activations[i], dropout_rates[i], True)\n",
    "            for i in range(len(hidden_dims))\n",
    "        ])\n",
    "        self.readout = MLPReadout(hidden_dims[-1], n_classes)\n",
    "        # New linear layer to combine graph-level features with enhanced features\n",
    "        self.combined_linear = nn.Linear(hidden_dims[-1] + extra_feat_dim, n_classes)\n",
    "\n",
    "    def forward(self, g, node_features, edge_features):\n",
    "        # Graph convolutional layers\n",
    "        h = g.ndata['feat']\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        hg = dgl.mean_nodes(g, 'h')\n",
    "\n",
    "        # Combine graph-level features with node and edge features\n",
    "        combined_features = torch.cat((hg, node_features, edge_features), dim=1)\n",
    "        logits = self.combined_linear(combined_features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset:  Abide100Dataset\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a90619fbe7f4438a027c7eb28c24d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.9162s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-33c91385b45c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    graphs, labels, node_features, edge_features = map(list, zip(*batch))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.tensor(labels)\n",
    "    # Convert node and edge features from list of numpy arrays to a single tensor\n",
    "    node_features = torch.tensor(np.array(node_features), dtype=torch.float32)\n",
    "    edge_features = torch.tensor(np.array(edge_features), dtype=torch.float32)\n",
    "    return batched_graph, labels, node_features, edge_features\n",
    "\n",
    "def extract_enhanced_features(graphs, df_nodes, df_edges, global_median_node, global_median_edge, centrality_significance):\n",
    "    # First, aggregate node data to ensure uniqueness\n",
    "    aggregated_nodes = aggregate_node_data(df_nodes)\n",
    "    \n",
    "    edge_diffs = {\n",
    "        ast.literal_eval(edge): (diff, p_val)\n",
    "        for edge, diff, p_val in zip(df_edges['Edge Pairs'], df_edges['Mean Difference'], df_edges['P-Value'])\n",
    "    }\n",
    "    \n",
    "    node_diffs = aggregated_nodes.set_index('Node')[['Mean Difference', 'Adjusted P-Value']].to_dict('index')\n",
    "    \n",
    "    features = []\n",
    "    for graph in graphs:\n",
    "        nx_graph = to_simple_graph(graph)\n",
    "        graph_features = []\n",
    "        \n",
    "        # Adjusted for node features considering centrality significance\n",
    "        for node, attrs in node_diffs.items():\n",
    "            centrality_factor = centrality_significance.get(node, 1)\n",
    "            if nx_graph.has_node(node):\n",
    "                diff = attrs['Mean Difference'] * centrality_factor\n",
    "                p_val = attrs['Adjusted P-Value']\n",
    "                graph_features.extend([diff * transform_p_value(p_val)])\n",
    "            else:\n",
    "                graph_features.extend([global_median_node * centrality_factor])\n",
    "        \n",
    "        # Adjusted for edge features considering centrality significance\n",
    "        for edge, values in edge_diffs.items():\n",
    "            centrality_factor = centrality_significance.get(edge, 1)\n",
    "            if nx_graph.has_edge(*edge):\n",
    "                diff, p_val = values\n",
    "                diff *= centrality_factor\n",
    "                graph_features.extend([diff * transform_p_value(p_val)])\n",
    "            else:\n",
    "                graph_features.extend([global_median_edge * centrality_factor])\n",
    "        \n",
    "        features.append(graph_features)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def to_simple_graph(dgl_graph):\n",
    "    g = dgl.to_networkx(dgl_graph)\n",
    "    simple_graph = nx.Graph()\n",
    "    for u, v, data in g.edges(data=True):\n",
    "        w = data.get('weight', 1.0)  # Default weight is 1.0 if 'weight' attribute is missing\n",
    "        if simple_graph.has_edge(u, v):\n",
    "            simple_graph[u][v]['weight'] += w\n",
    "        else:\n",
    "            simple_graph.add_edge(u, v, weight=w)\n",
    "    return simple_graph\n",
    "\n",
    "def transform_p_value(p_val):\n",
    "    return -np.log10(p_val)\n",
    "\n",
    "def compute_centrality_significance(df_nodes, df_edges):\n",
    "    centrality_significance = defaultdict(int)\n",
    "    for node in df_nodes['Node']:\n",
    "        centrality_significance[node] += 1\n",
    "    for edge in df_edges['Edge Pairs'].apply(ast.literal_eval):\n",
    "        centrality_significance[edge] += 1\n",
    "    return centrality_significance\n",
    "\n",
    "def aggregate_node_data(df):\n",
    "    # Aggregating 'Mean Difference' by sum and averaging 'Adjusted P-Value'\n",
    "    aggregated_data = df.groupby('Node').agg({\n",
    "        'Mean Difference': 'sum',\n",
    "        'Adjusted P-Value': 'mean'\n",
    "    }).reset_index()\n",
    "    return aggregated_data\n",
    "\n",
    "\n",
    "# Load CSV files for nodes and edges with their respective metrics\n",
    "df_nodes = pd.read_csv('significant_nodes.csv')\n",
    "df_edges = pd.read_csv('significant_edges.csv')\n",
    "\n",
    "# Assuming BrainDataset is already loaded as `Abide100`\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Calculate centrality significance\n",
    "centrality_significance = compute_centrality_significance(df_nodes, df_edges)\n",
    "\n",
    "# Compute global medians for nodes and edges\n",
    "global_median_node = np.median(df_nodes['Mean Difference'].values)\n",
    "global_median_edge = np.median(df_edges['Mean Difference'].values)\n",
    "\n",
    "# Extract enhanced features for all graphs\n",
    "X_enhanced = extract_enhanced_features(graphs, df_nodes, df_edges, global_median_node, global_median_edge, centrality_significance)\n",
    "\n",
    "# Split the dataset into training and test sets along with their enhanced features\n",
    "X_train, X_test, y_train, y_test, features_train, features_test = train_test_split(graphs, labels, X_enhanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the enhanced dataset including node and edge features for both training and testing\n",
    "class EnhancedGraphDataset(Dataset):\n",
    "    def __init__(self, graphs, labels, features):\n",
    "        self.graphs = graphs\n",
    "        self.labels = labels\n",
    "        self.features = features  # This now represents your enhanced features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx], self.features[idx]  # Update this line as per your needs\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    graphs, labels, features = map(list, zip(*batch))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    features = torch.tensor(features, dtype=torch.float32)  # Ensure features are tensors\n",
    "    return batched_graph, labels, features\n",
    "\n",
    "# Create instances of EnhancedGraphDataset for training and testing\n",
    "train_dataset = EnhancedGraphDataset(X_train, y_train, features_train)\n",
    "test_dataset = EnhancedGraphDataset(X_test, y_test, features_test)\n",
    "\n",
    "# DataLoaders for training and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Example dimensionality, adjust according to your actual feature sizes\n",
    "node_features_dim = features_train.shape[1]\n",
    "edge_features_dim = features_train.shape[1]  # Update this with correct edge feature dimension\n",
    "extra_feat_dim = node_features_dim + edge_features_dim\n",
    "\n",
    "model = GCNModel(\n",
    "    in_dim=Abide100.node_feat_dim, \n",
    "    hidden_dims=[64, 64],  \n",
    "    n_classes=2,           \n",
    "    dropout_rates=[0.5, 0.5],\n",
    "    activations=[F.relu, F.relu],\n",
    "    extra_feat_dim=extra_feat_dim  # Include the extra feature dimension\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batched_graph, labels, node_features, edge_features in train_dataloader:\n",
    "        logits = model(batched_graph, node_features, edge_features)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels, node_features, edge_features in test_dataloader:\n",
    "        logits = model(batched_graph, node_features, edge_features)\n",
    "        probabilities = torch.softmax(logits, dim=1)[:, 1]\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predictions.extend(probabilities.numpy())\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calculate accuracy\n",
    "predicted_labels = np.round(all_predictions)\n",
    "accuracy = accuracy_score(all_labels, predicted_labels)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, n_classes, num_heads, dropout_rate):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Correctly calculate the input and output dimensions for each layer\n",
    "        self.layers.append(dglnn.GATConv(in_dim, hidden_dims[0] // num_heads[0], num_heads=num_heads[0]))\n",
    "        for i in range(1, len(hidden_dims)):\n",
    "            # Corrected to handle the multiplicative effect of num_heads on the feature size\n",
    "            self.layers.append(dglnn.GATConv(\n",
    "                hidden_dims[i-1] * num_heads[i-1],\n",
    "                hidden_dims[i] // num_heads[i],\n",
    "                num_heads=num_heads[i]))\n",
    "        \n",
    "        # Output layer handling\n",
    "        self.classifier = nn.Linear(hidden_dims[-1] * num_heads[-1], n_classes)\n",
    "    \n",
    "    def forward(self, g):\n",
    "        h = g.ndata['feat']\n",
    "        for layer in self.layers[:-1]:\n",
    "            h = layer(g, h).view(h.size(0), -1)  # Flatten operation adjusted for attention heads\n",
    "            h = self.dropout(F.elu(h))\n",
    "        h = self.layers[-1](g, h).mean(1)  # Aggregate head outputs only in the last layer\n",
    "        h = self.dropout(h)\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset:  Abide100Dataset\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d78d3c4d57449c486b189b0ba862005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.0649s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3200x256 and 1024x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-f0c87067e1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-8436fe410ae8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten operation adjusted for attention heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Aggregate head outputs only in the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/dgl/nn/pytorch/conv/gatconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, edge_weight, get_attention)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0msrc_prefix_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdst_prefix_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mh_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 feat_src = feat_dst = self.fc(h_src).view(\n\u001b[0m\u001b[1;32m    314\u001b[0m                     \u001b[0;34m*\u001b[0m\u001b[0msrc_prefix_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3200x256 and 1024x256)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming BrainDataset, GCNModel, and all necessary functions are defined above\n",
    "\n",
    "# Add to your existing imports\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Early stopping criteria parameters\n",
    "patience = 5\n",
    "min_delta = 0.001\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopper = EarlyStopping(patience=patience, min_delta=min_delta)\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graphs, labels):\n",
    "        self.graphs = graphs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx], self.labels[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    graphs, labels = map(list, zip(*batch))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.tensor(labels)\n",
    "    return batched_graph, labels\n",
    "\n",
    "# Load the dataset\n",
    "Abide100 = BrainDataset('Abide100Dataset')\n",
    "graphs, labels = zip(*[(graph, label) for graph, label in Abide100])\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "indices = list(range(len(graphs)))\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_indices, temp_indices, train_labels, temp_labels = train_test_split(indices, labels, test_size=0.4, random_state=42)\n",
    "val_indices, test_indices, val_labels, test_labels = train_test_split(temp_indices, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Prepare the datasets\n",
    "train_graphs = [graphs[i] for i in train_indices]\n",
    "val_graphs = [graphs[i] for i in val_indices]\n",
    "test_graphs = [graphs[i] for i in test_indices]\n",
    "\n",
    "train_labels = [labels[i] for i in train_indices]\n",
    "val_labels = [labels[i] for i in val_indices]\n",
    "test_labels = [labels[i] for i in test_indices]\n",
    "\n",
    "train_dataset = GraphDataset(train_graphs, train_labels)\n",
    "val_dataset = GraphDataset(val_graphs, val_labels)\n",
    "test_dataset = GraphDataset(test_graphs, test_labels)\n",
    "\n",
    "# Prepare the DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Adjust model initialization with increased complexity\n",
    "# Corrected model initialization\n",
    "model = GATModel(\n",
    "    in_dim=Abide100.node_feat_dim,\n",
    "    hidden_dims=[256, 256, 128, 128],  # Increased model complexity\n",
    "    n_classes=2,\n",
    "    num_heads=[4, 4, 6, 6],  # Number of attention heads for each layer\n",
    "    dropout_rate=0.6  # Correct parameter name and value\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "early_stopper = EarlyStopping(patience=5, min_delta=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005) \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "val_loss_min = np.Inf \n",
    "\n",
    "# Training Loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        logits = model(batched_graph)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, labels in val_dataloader:\n",
    "            logits = model(batched_graph)\n",
    "            val_loss += loss_fn(logits, labels).item()\n",
    "    \n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_dataloader)}, Val Loss: {val_loss}\")\n",
    "\n",
    "    if val_loss < val_loss_min:\n",
    "        print(f'Validation loss decreased ({val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model\n",
    "        val_loss_min = val_loss\n",
    "    \n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    scheduler.step(val_loss)  # Learning rate scheduler step\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batched_graph, labels in test_dataloader:\n",
    "        logits = model(batched_graph)\n",
    "        probabilities = torch.softmax(logits, dim=1)[:, 1]\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predictions.extend(probabilities.numpy())\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calculate accuracy\n",
    "predicted_labels = np.round(all_predictions)\n",
    "accuracy = accuracy_score(all_labels, predicted_labels)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
